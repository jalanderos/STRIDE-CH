{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27054106-5f21-4f2a-a320-a24b0e6d0b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sunpy.map\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "from sunpy.net import Fido, attrs as a\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from matplotlib import colormaps, pyplot as plt\n",
    "\n",
    "import prepare_data\n",
    "import detect\n",
    "import plot_detection\n",
    "from settings import *\n",
    "\n",
    "\n",
    "pio.renderers.default = 'vscode'\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1324d19-b50d-43d3-8875-f4f0ea184bcb",
   "metadata": {},
   "source": [
    "# Data Inspection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f7089cf",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdf30f18",
   "metadata": {},
   "source": [
    "Extract Data from File System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6598a-c954-4bcc-9383-d6ab03b6364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract He I observation datetimes from FITS files\n",
    "HE_DATE_LIST = prepare_data.get_fits_date_list(\n",
    "    DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    ")\n",
    "\n",
    "# Extract magnetogram datetimes from 6302l FITS files\n",
    "MAG_DATE_LIST = prepare_data.get_fits_date_list(\n",
    "    DATE_RANGE, ALL_MAG_DIR, SELECT_MAG_DIR\n",
    ")\n",
    "\n",
    "# Extract EUV datetimes from FITS files\n",
    "EUV_DATE_LIST = prepare_data.get_fits_date_list(\n",
    "    DATE_RANGE, ALL_EUV_DIR, SELECT_EUV_DIR\n",
    ")\n",
    "\n",
    "if HE_DATE_LIST or EUV_DATE_LIST:\n",
    "    date_strs = [HE_DATE_LIST[0], HE_DATE_LIST[-1]]\n",
    "    file_date_str = f'{date_strs[0]}_{date_strs[-1]}'\n",
    "\n",
    "    num_maps = len(HE_DATE_LIST)\n",
    "    datetimes = [datetime.strptime(date_str, DICT_DATE_STR_FORMAT)\n",
    "                for date_str in date_strs]\n",
    "    title_date_strs = [datetime.strftime(d, '%m/%d/%Y') for d in datetimes]\n",
    "    DATE_RANGE_SUPTITLE = (f'{num_maps} Maps Evaluated from '\n",
    "                        + f'{title_date_strs[0]} to {title_date_strs[-1]}')\n",
    "else:\n",
    "    print('No data is available for the configured date range.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EUV Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain dates to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify datetimes to download\n",
    "# Idenitfy He I observation datetimes\n",
    "available_he_dates = [\n",
    "    datetime.strptime(date_str, DICT_DATE_STR_FORMAT).date()\n",
    "    for date_str in HE_DATE_LIST\n",
    "]\n",
    "\n",
    "# Identify missing dates between He I observations with a place holder hour\n",
    "days_in_period = (available_he_dates[-1] - available_he_dates[0]).days\n",
    "all_period_dates = set(available_he_dates[0] + timedelta(num_days)\n",
    "                       for num_days in range(days_in_period + 1))\n",
    "missing_he_dates = all_period_dates - set(available_he_dates)\n",
    "missing_date_str_list = [\n",
    "    datetime.strftime(missing_date, DICT_DATE_STR_FORMAT)\n",
    "    for missing_date in missing_he_dates\n",
    "]\n",
    "missing_date_str_list = [\n",
    "    missing_date_str[:12] + '16_00'\n",
    "    for missing_date_str in missing_date_str_list\n",
    "]\n",
    "\n",
    "all_period_date_str_list = HE_DATE_LIST + missing_date_str_list\n",
    "all_period_date_str_list.sort()\n",
    "\n",
    "# Identify datetimes to download EUV that have not yet been downloaded\n",
    "available_euv_dates = [\n",
    "    datetime.strptime(date_str, DICT_DATE_STR_FORMAT).date()\n",
    "    for date_str in EUV_DATE_LIST\n",
    "]\n",
    "download_euv_date_list = [\n",
    "    date_str for date_str, available_date\n",
    "    in zip(all_period_date_str_list, all_period_dates)\n",
    "    if available_date not in available_euv_dates\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Datetimes to Download for EUV Observations:')\n",
    "prepare_data.display_dates(download_euv_date_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data.download_euv(\n",
    "    download_euv_date_list, EUV_DATE_LIST, sat='SOHO',\n",
    "    output_dir=ALL_EUV_DIR, hr_window=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat = 'SOHO'\n",
    "euv_date_str = '2003_07_28__17_58'\n",
    "hr_window = 2\n",
    "\n",
    "center_date = datetime.strptime(euv_date_str, DICT_DATE_STR_FORMAT)\n",
    "        \n",
    "min_date = center_date - timedelta(hours=hr_window)\n",
    "max_date = center_date + timedelta(hours=hr_window)\n",
    "time_range = a.Time(min_date, max_date)\n",
    "cadence = a.Sample(30*u.minute)\n",
    "\n",
    "if sat == 'SOHO':\n",
    "    result = Fido.search(\n",
    "        time_range,\n",
    "        a.Instrument.eit, a.Wavelength(195*u.angstrom),\n",
    "        cadence\n",
    "    )\n",
    "else: # sat == SDO\n",
    "    result = Fido.search(\n",
    "        time_range,\n",
    "        a.Instrument.aia, a.Wavelength(193*u.angstrom),\n",
    "        cadence\n",
    "    )\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_num = -1\n",
    "\n",
    "Fido.fetch(result[:, row_num], path=ALL_EUV_DIR+'{file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all gzipped files after renaming\n",
    "remove_gzip = True\n",
    "\n",
    "# Rename all He, magnetogram, and EUV FITS files to include\n",
    "# observation date in title\n",
    "prepare_data.rename_dir(ALL_HE_DIR, remove_gzip)\n",
    "prepare_data.rename_dir(ALL_MAG_DIR, remove_gzip)\n",
    "prepare_data.rename_dir(ALL_EUV_DIR, remove_gzip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(HE_DATE_LIST)} Available Datetimes for He I Observations:')\n",
    "prepare_data.display_dates(HE_DATE_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(MAG_DATE_LIST)} Available Datetimes for Magnetograms:')\n",
    "prepare_data.display_dates(MAG_DATE_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(EUV_DATE_LIST)} Available Datetimes for EUV Observations:')\n",
    "prepare_data.display_dates(EUV_DATE_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('He I Observation Coverage: '\n",
    "      f'{len(HE_DATE_LIST)/len(EUV_DATE_LIST)*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation Comparison: He, Mag, EUV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_size_percent = 10\n",
    "\n",
    "for he_date_str in HE_DATE_LIST[:1]:\n",
    "    # he_date_str = '2003_07_14__18_07'\n",
    "\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    euv_date_str = prepare_data.get_nearest_date_str(\n",
    "        date_str_list=EUV_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "\n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    )\n",
    "    mag_fits_file = prepare_data.get_fits_path(\n",
    "        mag_date_str, DATE_RANGE, ALL_MAG_DIR, SELECT_MAG_DIR\n",
    "    )\n",
    "    euv_fits_file = prepare_data.get_fits_path(\n",
    "        euv_date_str, DATE_RANGE, ALL_EUV_DIR, SELECT_EUV_DIR\n",
    "    )\n",
    "    he_map = prepare_data.get_nso_sunpy_map(he_fits_file)\n",
    "    mag_map = prepare_data.get_nso_sunpy_map(mag_fits_file)\n",
    "    euv_map = sunpy.map.Map(euv_fits_file)\n",
    "\n",
    "    # Process magnetogram\n",
    "    smoothed_mag_map = prepare_data.get_smoothed_map(mag_map, smooth_size_percent)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "    \n",
    "    plot_detection.plot_he_map(fig, (1, 3, 1), he_map, he_date_str)\n",
    "\n",
    "    ax = fig.add_subplot(132, projection=mag_map)\n",
    "    mag_map.plot(axes=ax, vmin=-50, vmax=50, title=mag_date_str)\n",
    "    plot_detection.plot_map_contours(ax, smoothed_mag_map)\n",
    "    \n",
    "    plot_detection.plot_euv_map(fig, (1, 3, 3), euv_map, euv_date_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24becfa3-4634-43f1-b5c5-9c463459948c",
   "metadata": {},
   "source": [
    "# Data Products"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e11b12e6",
   "metadata": {},
   "source": [
    "## Pre-Processed Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d74c3567",
   "metadata": {},
   "source": [
    "### Pre-Processed Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.1-v0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "if not os.path.isdir(PREPROCESS_SAVE_DIR):\n",
    "    os.makedirs(PREPROCESS_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    if os.path.isfile(pre_process_file) and not overwrite:\n",
    "        print((f'He {he_date_str} pre-processed map already exists.'))\n",
    "        continue\n",
    "    \n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    ) \n",
    "    he_map_data = prepare_data.get_image_from_fits(he_fits_file)\n",
    "    \n",
    "    # pre_processed_map_data = detect.pre_process_v0_1(he_map_data)[0]\n",
    "    pre_processed_map_data = detect.pre_process_v0_4(he_map_data)\n",
    "    \n",
    "    save_list = [he_date_str, pre_processed_map_data]\n",
    "    np.save(pre_process_file, np.array(save_list, dtype=object), \n",
    "            allow_pickle=True)\n",
    "    print(f'{he_date_str} Pre-Processed Map Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "\n",
    "if not os.path.isdir(PREPROCESS_MAP_SAVE_DIR):\n",
    "    os.makedirs(PREPROCESS_MAP_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    pre_process_file = (PREPROCESS_MAP_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.fits')\n",
    "    if os.path.isfile(pre_process_file) and not overwrite:\n",
    "        print((f'He {he_date_str} pre-processed map already exists.'))\n",
    "        continue\n",
    "    \n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    )\n",
    "    he_map = prepare_data.get_nso_sunpy_map(he_fits_file)\n",
    "    \n",
    "    pre_processed_map = detect.pre_process_v0_5_1(he_map)\n",
    "    \n",
    "    pre_processed_map.save(pre_process_file, overwrite=overwrite)\n",
    "    print(f'{he_date_str} Pre-Processed Map Saved')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "if not os.path.isdir(PREPROCESS_MAP_SAVE_DIR):\n",
    "    os.makedirs(PREPROCESS_MAP_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    pre_process_file = (PREPROCESS_MAP_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.fits')\n",
    "    if os.path.isfile(pre_process_file) and not overwrite:\n",
    "        print((f'He {he_date_str} pre-processed map already exists.'))\n",
    "        continue\n",
    "    \n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    )\n",
    "    he_map = prepare_data.get_nso_sunpy_map(he_fits_file)\n",
    "    \n",
    "    pre_processed_map = detect.pre_process_vY(he_map)\n",
    "    \n",
    "    pre_processed_map.save(pre_process_file, overwrite=overwrite)\n",
    "    print(f'{he_date_str} Pre-Processed Map Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EUV Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "if not os.path.isdir(PREPROCESS_SAVE_DIR):\n",
    "    os.makedirs(PREPROCESS_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    euv_date_str = prepare_data.get_nearest_date_str(\n",
    "        EUV_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    if os.path.isfile(pre_process_file) and not overwrite:\n",
    "        print((f'He {he_date_str} pre-processed map already exists.'))\n",
    "        continue\n",
    "\n",
    "    ratio_fits_file = f'{RATIO_SAVE_DIR}He{he_date_str}_EUV{euv_date_str}.fits'\n",
    "\n",
    "    ratio_map_data = prepare_data.get_image_from_fits(ratio_fits_file)\n",
    "    \n",
    "    # pre_processed_map_data = detect.pre_process_v0_1(ratio_map_data)[0]\n",
    "    pre_processed_map_data = detect.pre_process_v0_4(ratio_map_data)\n",
    "    \n",
    "    save_list = [he_date_str, pre_processed_map_data]\n",
    "    np.save(pre_process_file, np.array(save_list, dtype=object), \n",
    "            allow_pickle=True)\n",
    "    print(f'{he_date_str} Pre-Processed Map Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprojected Magnetograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differential rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "smooth_size_percent = 10\n",
    "\n",
    "if not os.path.isdir(ROTATED_MAG_SAVE_DIR):\n",
    "    os.makedirs(ROTATED_MAG_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    fits_file_name = f'{ROTATED_MAG_SAVE_DIR}Mag{mag_date_str}_He{he_date_str}'\n",
    "    reprojected_fits_file = f'{fits_file_name}.fits'\n",
    "    reprojected_smooth_fits_file = f'{fits_file_name}_smooth.fits'\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    if (os.path.isfile(reprojected_fits_file) or \\\n",
    "        os.path.isfile(reprojected_smooth_fits_file)) and not overwrite:\n",
    "        print((f'{mag_date_str} magnetogram reprojected '\n",
    "                + f'to {he_date_str} already exists.'))\n",
    "        continue\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_map = prepare_data.get_nso_sunpy_map(ALL_HE_DIR + he_date_str + '.fts')\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "    \n",
    "    # Extract Magnetogram observation\n",
    "    mag_map = prepare_data.get_nso_sunpy_map(ALL_MAG_DIR + mag_date_str + '.fts')\n",
    "\n",
    "    # Process magnetogram\n",
    "    reprojected_mag_map = prepare_data.diff_rotate(\n",
    "        input_map=mag_map, target_map=he_map\n",
    "    )\n",
    "    \n",
    "    smoothed_map = prepare_data.get_smoothed_map(mag_map, smooth_size_percent)\n",
    "    reprojected_smooth_map = prepare_data.diff_rotate(\n",
    "        input_map=smoothed_map, target_map=he_map\n",
    "    )\n",
    "    \n",
    "    # Save to FITS files\n",
    "    reprojected_mag_map.save(reprojected_fits_file, overwrite=overwrite)\n",
    "    reprojected_smooth_map.save(f'{fits_file_name}_smooth.fits', overwrite=overwrite)\n",
    "    print(f'{mag_date_str} magnetogram reprojected to {he_date_str} maps saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heliographic reprojection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "smooth_size_percent = 10\n",
    "\n",
    "if not os.path.isdir(HELIOGRAPH_MAG_SAVE_DIR):\n",
    "    os.makedirs(HELIOGRAPH_MAG_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    fits_file_name = f'{HELIOGRAPH_MAG_SAVE_DIR}Mag{mag_date_str}_He{he_date_str}'\n",
    "    reprojected_fits_file = f'{fits_file_name}.fits'\n",
    "    reprojected_smooth_fits_file = f'{fits_file_name}_smooth.fits'\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    if (os.path.isfile(reprojected_fits_file) or \\\n",
    "        os.path.isfile(reprojected_smooth_fits_file)) and not overwrite:\n",
    "        print((f'{mag_date_str} magnetogram reprojected '\n",
    "                + f'to {he_date_str} already exists.'))\n",
    "        continue\n",
    "    \n",
    "    # Extract observations\n",
    "    pre_process_file = (PREPROCESS_MAP_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.fits')\n",
    "    pre_processed_map = sunpy.map.Map(pre_process_file)\n",
    "    \n",
    "    mag_fits_file = prepare_data.get_fits_path(\n",
    "        mag_date_str, DATE_RANGE, ALL_MAG_DIR, SELECT_MAG_DIR\n",
    "    )\n",
    "    mag_map = prepare_data.get_nso_sunpy_map(mag_fits_file)\n",
    "\n",
    "    # Process magnetogram\n",
    "    hg_mag_map = detect.reproject_to_cea(mag_map)\n",
    "    reprojected_mag_map = hg_mag_map.reproject_to(\n",
    "        pre_processed_map.wcs, algorithm='adaptive'\n",
    "    )\n",
    "    \n",
    "    smoothed_map = prepare_data.get_smoothed_map(mag_map, smooth_size_percent)\n",
    "    hg_smoothed_map = detect.reproject_to_cea(smoothed_map)\n",
    "    reprojected_smooth_map = hg_smoothed_map.reproject_to(\n",
    "        pre_processed_map.wcs, algorithm='adaptive'\n",
    "    )\n",
    "    \n",
    "    # Save to FITS files\n",
    "    reprojected_mag_map.save(reprojected_fits_file, overwrite=overwrite)\n",
    "    reprojected_smooth_map.save(reprojected_smooth_fits_file, overwrite=overwrite)\n",
    "    print(f'{mag_date_str} magnetogram reprojected to {he_date_str} map saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### He I/EUV Ratio Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "\n",
    "if not os.path.isdir(RATIO_SAVE_DIR):\n",
    "    os.makedirs(RATIO_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "\n",
    "    euv_date_str = prepare_data.get_nearest_date_str(\n",
    "        EUV_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    ratio_fits_file = f'{RATIO_SAVE_DIR}He{he_date_str}_EUV{euv_date_str}.fits'\n",
    "    if os.path.isfile(ratio_fits_file):\n",
    "        if overwrite:\n",
    "            os.remove(ratio_fits_file)\n",
    "        else:\n",
    "            print((f'{he_date_str} to {euv_date_str} ratio already exists.'))\n",
    "            continue\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    )\n",
    "    he_map = prepare_data.get_nso_sunpy_map(he_fits_file)\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "    \n",
    "    # Remove error causing keywords which have invalid ascii content\n",
    "    he_map.meta.pop('history')\n",
    "    he_map.meta.pop('comment')\n",
    "    \n",
    "    # Extract and reproject EUV observation\n",
    "    euv_fits_file = prepare_data.get_fits_path(\n",
    "        euv_date_str, DATE_RANGE, ALL_EUV_DIR, SELECT_EUV_DIR\n",
    "    )\n",
    "    euv_map = sunpy.map.Map(euv_fits_file)\n",
    "    reprojected_euv_map = prepare_data.diff_rotate(\n",
    "        input_map=euv_map, target_map=he_map\n",
    "    )\n",
    "    \n",
    "    # Pre-process He I data via background removal and upper cutoff\n",
    "    # Satisfactory only for Sarnoff camera observations\n",
    "    he_map_data = np.where(he_map.data == he_map.data[0,0],\n",
    "                           np.nan, he_map.data)\n",
    "    he_map_data = np.where(he_map_data >= np.percentile(he_map_data, 99.9),\n",
    "                           np.nan, he_map_data)\n",
    "    \n",
    "    ratio_data = np.divide(he_map_data, (reprojected_euv_map.data)**0.5)\n",
    "    ratio_map = sunpy.map.Map(ratio_data, he_map.meta)\n",
    "    \n",
    "    # Save to FITS files\n",
    "    ratio_map.save(ratio_fits_file)\n",
    "    print(f'He{he_date_str} to EUV{euv_date_str} ratio saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.2-v0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "percent_of_peak = 80\n",
    "morph_radius = 18\n",
    "\n",
    "\n",
    "if not os.path.isdir(DETECTION_SAVE_DIR):\n",
    "    os.makedirs(DETECTION_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    mask_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    if os.path.isfile(mask_file) and not overwrite:\n",
    "        print((f'He {he_date_str} single mask already exists.'))\n",
    "        continue\n",
    "    \n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    pre_processed_map = np.load(pre_process_file, allow_pickle=True)[-1]\n",
    "\n",
    "    ch_mask = detect.get_ch_mask(\n",
    "        pre_processed_map, percent_of_peak, morph_radius\n",
    "    )\n",
    "    \n",
    "    save_list = [he_date_str, ch_mask]\n",
    "    np.save(mask_file, np.array(save_list, dtype=object), allow_pickle=True)\n",
    "    print(f'{he_date_str} Single Mask Saved')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53525df2",
   "metadata": {},
   "source": [
    "### Ensemble Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.2-v0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "\n",
    "# percent_of_peak_list = [80,80, 90, 100,100]\n",
    "# morph_radius_list = [18,20, 16, 16,20]\n",
    "percent_of_peak_list = [100,100, 110, 120,120]\n",
    "morph_radius_list = [18,20, 16, 16,20]\n",
    "\n",
    "\n",
    "if not os.path.isdir(DETECTION_SAVE_DIR):\n",
    "    os.makedirs(DETECTION_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    if os.path.isfile(ensemble_file) and not overwrite:\n",
    "        print((f'He {he_date_str} ensemble map already exists.'))\n",
    "        continue\n",
    "    \n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    pre_processed_map = np.load(pre_process_file, allow_pickle=True)[-1]\n",
    "\n",
    "    # ensemble_map_data = detect.get_ensemble_v0_2(\n",
    "    #     pre_processed_map, percent_of_peak_list, morph_radius_list\n",
    "    # )[0]\n",
    "    ensemble_map_data = detect.get_ensemble_v0_3(\n",
    "        pre_processed_map, percent_of_peak_list, morph_radius_list\n",
    "    )[0]\n",
    "    \n",
    "    save_list = [he_date_str, ensemble_map_data]\n",
    "    np.save(ensemble_file, np.array(save_list, dtype=object), allow_pickle=True)\n",
    "    print(f'{he_date_str} Ensemble Map Saved')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "percent_of_peak_list = [80,80, 90, 100,100]\n",
    "morph_radius_list = [18,20, 16, 16,20]\n",
    "unipolarity_threshold = 0.5\n",
    "\n",
    "\n",
    "if not os.path.isdir(DETECTION_SAVE_DIR):\n",
    "    os.makedirs(DETECTION_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    if os.path.isfile(ensemble_file) and not overwrite:\n",
    "        print((f'He {he_date_str} ensemble map already exists.'))\n",
    "        continue\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    )\n",
    "    he_map = prepare_data.get_nso_sunpy_map(he_fits_file)\n",
    "\n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    pre_processed_map_data = np.load(pre_process_file, allow_pickle=True)[-1]\n",
    "    pre_processed_map = sunpy.map.Map(\n",
    "        np.flipud(pre_processed_map_data), he_map.meta\n",
    "    )\n",
    "\n",
    "    # Extract saved processed magnetograms\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    reprojected_fits_file = (f'{ROTATED_MAG_SAVE_DIR}'\n",
    "                            f'Mag{mag_date_str}_He{he_date_str}.fits')\n",
    "    reprojected_mag_map = sunpy.map.Map(reprojected_fits_file)\n",
    "\n",
    "    ensemble_map_data = detect.get_ensemble_v0_5(\n",
    "        pre_processed_map, reprojected_mag_map,\n",
    "        percent_of_peak_list, morph_radius_list,\n",
    "        unipolarity_threshold\n",
    "    )[0]\n",
    "    \n",
    "    save_list = [he_date_str, ensemble_map_data]\n",
    "    np.save(ensemble_file, np.array(save_list, dtype=object), allow_pickle=True)\n",
    "    print(f'{he_date_str} Ensemble Map Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "# v0.5.1 Conservative Design\n",
    "# percent_of_peak_list = [80, 80, 90, 100]\n",
    "# morph_radius_list = [   15, 17, 13, 13] # Mm\n",
    "# unipolarity_threshold = 0.5\n",
    "\n",
    "# v0.5.1 Design\n",
    "percent_of_peak_list = [70, 70, 80, 90]\n",
    "morph_radius_list = [   15, 17, 13, 13] # Mm\n",
    "# unipolarity_threshold = 0.5\n",
    "unipolarity_threshold = 0\n",
    "\n",
    "# # v0.5.1 KPVT Design\n",
    "# percent_of_peak_list = [85, 105, 85, 95]\n",
    "# morph_radius_list = [   17, 13, 15, 13] # Mm\n",
    "# unipolarity_threshold = 0\n",
    "\n",
    "\n",
    "if not os.path.isdir(DETECTION_MAP_SAVE_DIR):\n",
    "    os.makedirs(DETECTION_MAP_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    ensemble_file = f'{DETECTION_MAP_SAVE_DIR}{he_date_str}_ensemble_map.fits'\n",
    "    if os.path.isfile(ensemble_file) and not overwrite:\n",
    "        print((f'He {he_date_str} ensemble map already exists.'))\n",
    "        continue\n",
    "    \n",
    "    # Extract pre-processed map\n",
    "    pre_process_file = (PREPROCESS_MAP_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.fits')\n",
    "    pre_processed_map = sunpy.map.Map(pre_process_file)\n",
    "\n",
    "    # Extract saved processed magnetograms\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    reprojected_fits_file = (f'{ROTATED_MAG_SAVE_DIR}'\n",
    "                             f'Mag{mag_date_str}_He{he_date_str}.fits')\n",
    "    reprojected_mag_map = sunpy.map.Map(reprojected_fits_file)\n",
    "\n",
    "    ensemble_map_data = detect.get_ensemble_v0_5_1(\n",
    "        pre_processed_map, reprojected_mag_map,\n",
    "        percent_of_peak_list, morph_radius_list,\n",
    "        unipolarity_threshold\n",
    "    )[0]\n",
    "    ensemble_map = sunpy.map.Map(\n",
    "        np.flipud(ensemble_map_data), pre_processed_map.meta\n",
    "    )\n",
    "    \n",
    "    ensemble_map.save(ensemble_file, overwrite=overwrite)\n",
    "    print(f'{he_date_str} Ensemble Map Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "# percent_of_peak_list = [  62, 68, 73, 80]\n",
    "# morph_radius_list = [11, 13,  8, 10]\n",
    "# unipolarity_threshold = 0.01\n",
    "percent_of_peak_list = [85, 73, 95, 85]\n",
    "morph_radius_list = [   10, 14, 10, 14]\n",
    "unipolarity_threshold = 0.5\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.isdir(DETECTION_MAP_SAVE_DIR):\n",
    "    os.makedirs(DETECTION_MAP_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    ensemble_file = f'{DETECTION_MAP_SAVE_DIR}{he_date_str}_ensemble_map.fits'\n",
    "    if os.path.isfile(ensemble_file) and not overwrite:\n",
    "        print((f'He {he_date_str} ensemble map already exists.'))\n",
    "        continue\n",
    "    \n",
    "    # Extract pre-processed map\n",
    "    pre_process_file = (PREPROCESS_MAP_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.fits')\n",
    "    pre_processed_map = sunpy.map.Map(pre_process_file)\n",
    "\n",
    "    # Extract saved processed magnetograms\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    reprojected_fits_file = (f'{HELIOGRAPH_MAG_SAVE_DIR}'\n",
    "                            f'Mag{mag_date_str}_He{he_date_str}.fits')\n",
    "    reprojected_mag_map = sunpy.map.Map(reprojected_fits_file)\n",
    "\n",
    "    ensemble_map_data = detect.get_ensemble_vY(\n",
    "        pre_processed_map, reprojected_mag_map,\n",
    "        percent_of_peak_list, morph_radius_list,\n",
    "        unipolarity_threshold\n",
    "    )[0]\n",
    "    ensemble_map = sunpy.map.Map(\n",
    "        np.flipud(ensemble_map_data), pre_processed_map.meta\n",
    "    )\n",
    "    \n",
    "    ensemble_map.save(ensemble_file, overwrite=overwrite)\n",
    "    print(f'{he_date_str} Ensemble Map Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Map Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for he_date_str in HE_DATE_LIST[:1]:\n",
    "    \n",
    "    # Extract observations and ratio map\n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    )\n",
    "    he_map = prepare_data.get_nso_sunpy_map(he_fits_file)\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "    \n",
    "    pre_process_file = (PREPROCESS_MAP_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.fits')\n",
    "    pre_processed_map = sunpy.map.Map(pre_process_file)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plot_detection.plot_he_map(fig, (1, 2, 1), he_map, he_date_str)\n",
    "    \n",
    "    ax = fig.add_subplot(122, projection=pre_processed_map)\n",
    "    pre_processed_map.plot(axes=ax, title=he_date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio Comparison: He I, EUV, & He I/EUV Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "out_dir = OUTPUT_DIR + 'Ratio_Comparison/' + DATE_DIR\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}He{he_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'He {he_date_str} ratio comparison already exists.'))\n",
    "        continue\n",
    "\n",
    "    euv_date_str = prepare_data.get_nearest_date_str(\n",
    "        EUV_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    # Extract observations and ratio map\n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    )\n",
    "    he_map = prepare_data.get_nso_sunpy_map(he_fits_file)\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "    \n",
    "    euv_fits_file = prepare_data.get_fits_path(\n",
    "        euv_date_str, DATE_RANGE, ALL_EUV_DIR, SELECT_EUV_DIR\n",
    "    )\n",
    "    euv_map = sunpy.map.Map(euv_fits_file)\n",
    "    \n",
    "    ratio_fits_file = f'{RATIO_SAVE_DIR}He{he_date_str}_EUV{euv_date_str}.fits'\n",
    "    ratio_map = sunpy.map.Map(ratio_fits_file)\n",
    "    \n",
    "    # Create panel plot\n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "    plot_detection.plot_he_map(fig, (1, 3, 1), he_map, he_date_str)\n",
    "\n",
    "    plot_detection.plot_euv_map(fig, (1, 3, 2), euv_map, euv_date_str)\n",
    "\n",
    "    ax = fig.add_subplot(133, projection=he_map)\n",
    "    ratio_map.plot(axes=ax, cmap='jet', vmin=-1, vmax=6)\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'He {he_date_str} map comparison saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Map Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Mask Comparison: Pre-Processed He I & Single Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = DETECTION_IMAGE_DIR + 'Preprocess_Single_Comparison/'\n",
    "\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    pre_processed_map = np.load(pre_process_file, allow_pickle=True)[-1]\n",
    "    \n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    ) \n",
    "    raw_he = prepare_data.get_image_from_fits(he_fits_file)\n",
    "    he = np.where(raw_he == raw_he[0,0], np.NaN, raw_he)\n",
    "    \n",
    "    mask_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    single_mask = np.load(mask_file, allow_pickle=True)[-1]\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    ax[0].set_title(he_date_str, fontsize=24)\n",
    "    ax[0].imshow(pre_processed_map, cmap=plt.cm.gray)\n",
    "    \n",
    "    ax[1].imshow(he, cmap=plt.cm.afmhot, vmin=-100, vmax=100)\n",
    "    ax[1].contour(single_mask, linewidths=2, cmap=plt.cm.gray)\n",
    "\n",
    "    plt.savefig(f'{out_dir}{he_date_str}.jpg')\n",
    "    plt.close(fig)\n",
    "    print(f'{he_date_str} map saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for euv_date_str in EUV_DATE_LIST[:1]:\n",
    "\n",
    "    he_date_str = prepare_data.get_latest_date_str(\n",
    "        HE_DATE_LIST, selected_date_str=euv_date_str\n",
    "    )\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_map = prepare_data.get_nso_sunpy_map(ALL_HE_DIR + he_date_str + '.fts')\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "    \n",
    "    he_base_data = np.where(he_map.data == he_map.data[0,0], np.nan, he_map.data)\n",
    "    he_base_map = sunpy.map.Map(he_base_data, he_map.meta)\n",
    "    \n",
    "    # Extract saved single mask array and convert to Sunpy map\n",
    "    mask_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    mask_data = np.load(mask_file, allow_pickle=True)[-1]\n",
    "    mask_map = sunpy.map.Map(np.flipud(mask_data), he_map.meta)\n",
    "    mask_map.plot_settings['cmap'] = colormaps['gray']\n",
    "    \n",
    "    euv_map = sunpy.map.Map(ALL_EUV_DIR + euv_date_str + '.fts')\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "    \n",
    "    plot_detection.plot_he_map(fig, (1, 3, 1), he_map, he_date_str)\n",
    "    \n",
    "    # Plot He I observation with overlayed detection contours\n",
    "    ax = fig.add_subplot(132, projection=he_map)\n",
    "    he_base_map.plot(axes=ax, vmin=-100, vmax=100, title=he_date_str,\n",
    "                     cmap='afmhot')\n",
    "    for contour in mask_map.contour(0):\n",
    "        ax.plot_coord(contour, color='black', linewidth=1)\n",
    "    \n",
    "    plot_detection.plot_euv_map(fig, (1, 3, 3), euv_map, euv_date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e729d01",
   "metadata": {},
   "source": [
    "#### Pre-Processed & Ensemble Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.2-v0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795460ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = DETECTION_IMAGE_DIR + 'Preprocess_Comparison/'\n",
    "\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    pre_processed_map = np.load(pre_process_file, allow_pickle=True)[-1]\n",
    "    \n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    ensemble_map = np.load(ensemble_file, allow_pickle=True)[-1]\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    ax[0].set_title(he_date_str, fontsize=24)\n",
    "    ax[0].imshow(pre_processed_map, cmap=plt.cm.gray)\n",
    "    \n",
    "    ax[1].imshow(ensemble_map, cmap=plt.cm.magma)\n",
    "\n",
    "    plt.savefig(f'{out_dir}{he_date_str}.jpg')\n",
    "    plt.close(fig)\n",
    "    print(f'{he_date_str} map saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = DETECTION_IMAGE_DIR + 'Preprocess_Comparison/'\n",
    "\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST[:1]:\n",
    "    \n",
    "    pre_process_file = (PREPROCESS_MAP_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.fits')\n",
    "    pre_processed_map = sunpy.map.Map(pre_process_file)\n",
    "    \n",
    "    ensemble_file = f'{DETECTION_MAP_SAVE_DIR}{he_date_str}_ensemble_map.fits'\n",
    "    ensemble_map = sunpy.map.Map(ensemble_file)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    ax = fig.add_subplot(1, 2, 1, projection=pre_processed_map)\n",
    "    pre_processed_map.plot(axes=ax, title=he_date_str)\n",
    "    \n",
    "    # Plot ensemble map with overlayed neutral lines\n",
    "    ax = fig.add_subplot(1, 2, 2, projection=ensemble_map)\n",
    "    ensemble_map.plot(axes=ax, title='', cmap='magma')\n",
    "\n",
    "    # plt.savefig(f'{out_dir}{he_date_str}.jpg')\n",
    "    # plt.close(fig)\n",
    "    # print(f'{he_date_str} map saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = DETECTION_IMAGE_DIR + 'Preprocess_Comparison/'\n",
    "\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    pre_process_file = (PREPROCESS_MAP_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.fits')\n",
    "    pre_processed_map = sunpy.map.Map(pre_process_file)\n",
    "    \n",
    "    ensemble_file = f'{DETECTION_MAP_SAVE_DIR}{he_date_str}_ensemble_map.fits'\n",
    "    ensemble_map = sunpy.map.Map(ensemble_file)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "    ax = fig.add_subplot(1, 5, (1,2), projection=pre_processed_map)\n",
    "    pre_processed_map.plot(axes=ax, title=he_date_str)\n",
    "    \n",
    "    # Plot ensemble map with overlayed neutral lines\n",
    "    ax = fig.add_subplot(1, 5, (3,5), projection=ensemble_map)\n",
    "    ensemble_map.plot(axes=ax, title='', cmap='magma')\n",
    "\n",
    "    plt.savefig(f'{out_dir}{he_date_str}.jpg')\n",
    "    plt.close(fig)\n",
    "    print(f'{he_date_str} map saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Comparison: He I, Ensemble, Magnetogram, & EUV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.2-v0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "out_dir = DETECTION_IMAGE_DIR + 'Full_Comparison/'\n",
    "smooth_size_percent = 10\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for euv_date_str in EUV_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}EUV{euv_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'EUV {euv_date_str} full comparison already exists.'))\n",
    "        continue\n",
    "\n",
    "    he_date_str = prepare_data.get_latest_date_str(\n",
    "        HE_DATE_LIST, selected_date_str=euv_date_str\n",
    "    )\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_map = prepare_data.get_nso_sunpy_map(ALL_HE_DIR + he_date_str + '.fts')\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "    \n",
    "    mag_map = prepare_data.get_nso_sunpy_map(ALL_MAG_DIR + mag_date_str + '.fts')\n",
    "    \n",
    "    # Extract and crop EUV map to similar zoom level to other observations \n",
    "    euv_map = sunpy.map.Map(ALL_EUV_DIR + euv_date_str + '.fts')\n",
    "    euv_map = euv_map.submap(\n",
    "        bottom_left=SkyCoord(\n",
    "            Tx=-1050*u.arcsec, Ty=-1050*u.arcsec,\n",
    "                 frame=euv_map.coordinate_frame\n",
    "        ),\n",
    "        top_right=SkyCoord(\n",
    "            Tx=1050*u.arcsec, Ty=1050*u.arcsec,\n",
    "            frame=euv_map.coordinate_frame\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Process magnetogram\n",
    "    smoothed_mag_map = prepare_data.get_smoothed_map(mag_map, smooth_size_percent)\n",
    "    \n",
    "    # Extract saved ensemble map array and convert to Sunpy map\n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    ensemble_map_data = np.load(ensemble_file, allow_pickle=True)[-1]\n",
    "    ensemble_map = sunpy.map.Map(np.flipud(ensemble_map_data), he_map.meta)\n",
    "    ensemble_map.plot_settings['cmap'] = colormaps['magma']\n",
    "    \n",
    "    fig = plt.figure(figsize=(24, 5))\n",
    "\n",
    "    plot_detection.plot_he_map(fig, (1, 4, 1), he_map, he_date_str)\n",
    "\n",
    "    ax = fig.add_subplot(142, projection=he_map)\n",
    "    ensemble_map.plot(axes=ax, title='')\n",
    "    \n",
    "    ax = fig.add_subplot(143, projection=mag_map)\n",
    "    mag_map.plot(axes=ax, vmin=-50, vmax=50, title=mag_date_str)\n",
    "    plot_detection.plot_map_contours(ax, smoothed_mag_map)\n",
    "    \n",
    "    plot_detection.plot_euv_map(fig, (1, 4, 4), euv_map, euv_date_str)\n",
    "    \n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f'{euv_date_str} map comparison saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Magnetic Comparison: He I, Ensemble, & Magnetogram with Inversion Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.2-v0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = DETECTION_IMAGE_DIR + 'Mag_Comparison/'\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST[-10:]:\n",
    "\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "\n",
    "    # Extract He I observation\n",
    "    he_map = prepare_data.get_nso_sunpy_map(ALL_HE_DIR + he_date_str + '.fts')\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "\n",
    "    # Extract saved processed magnetograms\n",
    "    mag_fits_name = f'{ROTATED_MAG_SAVE_DIR}Mag{mag_date_str}_He{he_date_str}'\n",
    "    reprojected_fits_file = f'{mag_fits_name}.fits'\n",
    "    reprojected_smooth_fits_file = f'{mag_fits_name}_smooth.fits'\n",
    "    reprojected_mag_map = sunpy.map.Map(reprojected_fits_file)\n",
    "    reprojected_smooth_map = sunpy.map.Map(reprojected_smooth_fits_file)\n",
    "\n",
    "    # Extract saved ensemble map array and convert to Sunpy map\n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    ensemble_map_data = np.load(ensemble_file, allow_pickle=True)[-1]\n",
    "    ensemble_map = sunpy.map.Map(np.flipud(ensemble_map_data), he_map.meta)\n",
    "    ensemble_map.plot_settings['cmap'] = colormaps['magma']\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "    plot_detection.plot_he_map(fig, (1, 3, 1), he_map, he_date_str)\n",
    "\n",
    "    ax = fig.add_subplot(132, projection=he_map)\n",
    "    ensemble_map.plot(axes=ax, title='')\n",
    "    plot_detection.plot_map_contours(ax, reprojected_smooth_map)\n",
    "\n",
    "    ax = fig.add_subplot(133, projection=he_map)\n",
    "    reprojected_mag_map.plot(axes=ax, vmin=-50, vmax=50, title=mag_date_str)\n",
    "    plot_detection.plot_map_contours(ax, reprojected_smooth_map)\n",
    "\n",
    "    plt.savefig(f'{out_dir}He{he_date_str}.jpg')\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f'{he_date_str} map comparison saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EUV Comparison: He I, Ensemble with Inversion Lines, & EUV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.2-v0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "out_dir = DETECTION_IMAGE_DIR + 'EUV_Comparison/'\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for euv_date_str in EUV_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}EUV{euv_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'EUV {euv_date_str} comparison already exists.'))\n",
    "        continue\n",
    "    \n",
    "    he_date_str = prepare_data.get_latest_date_str(\n",
    "        HE_DATE_LIST, selected_date_str=euv_date_str\n",
    "    )\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "    plot_detection.plot_he_neutral_lines_euv_comparison(\n",
    "        fig, he_date_str, mag_date_str, euv_date_str,\n",
    "        ROTATED_MAG_SAVE_DIR\n",
    "    )\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'{euv_date_str} map comparison saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.5.1+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "hg_reproject = False\n",
    "out_dir = DETECTION_IMAGE_DIR + 'EUV_Comparison/'\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for euv_date_str in EUV_DATE_LIST[:1]:\n",
    "    euv_date_str = '2003_07_14__16_12'\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}EUV{euv_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'EUV {euv_date_str} comparison already exists.'))\n",
    "        continue\n",
    "    \n",
    "    he_date_str = prepare_data.get_latest_date_str(\n",
    "        HE_DATE_LIST, selected_date_str=euv_date_str\n",
    "    )\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    if hg_reproject:\n",
    "        fig = plt.figure(figsize=(22, 5))\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(18, 5))\n",
    "    \n",
    "    plot_detection.plot_he_neutral_lines_euv_v0_5_1(\n",
    "        fig, he_date_str, mag_date_str, euv_date_str, hg_reproject=False\n",
    "    )\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'{euv_date_str} map comparison saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "# out_dir = (DETECTION_IMAGE_DIR + '_Version_Comparison'\n",
    "#            + DATE_DIR + 'v0_2_v0_4_Unipolar/')\n",
    "out_dir = (DETECTION_IMAGE_DIR + '_Version_Comparison'\n",
    "           + DATE_DIR + 'v0_5_v0_6/')\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# comparison_version_dir = DETECT_DIR + 'v0_1/' + 'Saved_npy_Files/'\n",
    "comparison_version_dir = DETECT_DIR + 'v0_5/' + 'Saved_npy_Files/'\n",
    "\n",
    "for euv_date_str in EUV_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}EUV{euv_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'EUV {euv_date_str} comparison already exists.'))\n",
    "        continue\n",
    "    \n",
    "    he_date_str = prepare_data.get_latest_date_str(\n",
    "        HE_DATE_LIST, selected_date_str=euv_date_str\n",
    "    )\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_map = prepare_data.get_nso_sunpy_map(ALL_HE_DIR + he_date_str + '.fts')\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "    \n",
    "    # Extract comparison saved ensemble map array and convert to Sunpy map\n",
    "    comparison_file = f'{comparison_version_dir}{he_date_str}_ensemble_map.npy'\n",
    "    comparison_map_data = np.load(comparison_file, allow_pickle=True)[-1]\n",
    "    comparison_map_data = np.where(np.isnan(ensemble_map_data), np.nan, comparison_map_data)\n",
    "    comparison_map = sunpy.map.Map(np.flipud(comparison_map_data), he_map.meta)\n",
    "    \n",
    "    # Extract saved ensemble map array and convert to Sunpy map\n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    ensemble_map_data = np.load(ensemble_file, allow_pickle=True)[-1]\n",
    "    ensemble_map = sunpy.map.Map(np.flipud(ensemble_map_data), he_map.meta)\n",
    "    ensemble_map.plot_settings['cmap'] = colormaps['magma']\n",
    "\n",
    "    \n",
    "    # Extract saved processed magnetogram\n",
    "    reprojected_smooth_file = (f'{ROTATED_MAG_SAVE_DIR}Mag{mag_date_str}'\n",
    "                               + f'_He{he_date_str}_smooth.fits')\n",
    "    reprojected_smooth_map = sunpy.map.Map(reprojected_smooth_file)\n",
    "    \n",
    "    euv_map = sunpy.map.Map(ALL_EUV_DIR + euv_date_str + '.fts')\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 11))\n",
    "    \n",
    "    # Plot He observation\n",
    "    plot_detection.plot_he_map(fig, (2, 2, 1), he_map, he_date_str)\n",
    "    \n",
    "    plot_detection.plot_euv_map(fig, (2, 2, 2), euv_map, euv_date_str)\n",
    "    \n",
    "    # Plot ensemble map with overlayed neutral lines\n",
    "    ax = fig.add_subplot(2, 2, 3, projection=he_map)\n",
    "    comparison_map.plot(axes=ax, title='v0.5')\n",
    "    plot_detection.plot_map_contours(ax, reprojected_smooth_map)\n",
    "    \n",
    "    # Plot ensemble map with overlayed neutral lines\n",
    "    ax = fig.add_subplot(2, 2, 4, projection=he_map)\n",
    "    ensemble_map.plot(axes=ax, title='v0.6')\n",
    "    plot_detection.plot_map_contours(ax, reprojected_smooth_map)\n",
    "\n",
    "    # Save plot\n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'{euv_date_str} map comparison saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_time_series_dict = detect.get_outcome_time_series_dict_v0_1(\n",
    "    HE_DATE_LIST, DETECTION_SAVE_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "region_num_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'Region_Number/',\n",
    "    'num_ch', 'viridis', 'Detected CH Number'\n",
    ")\n",
    "px_percent_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'EUV_Px_Percentage/',\n",
    "    'px_percent', 'plasma', 'Detected Pixel Percentage (%)'\n",
    ")\n",
    "area_percent_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'EUV_Area_Percentage/',\n",
    "    'area_percent', 'plasma', 'Detected Area Percentage (%)'\n",
    ")\n",
    "area_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'EUV_Area/',\n",
    "    'area', 'plasma', 'Detected Area (Mm^2)'\n",
    ")\n",
    "out_dir, outcome_key, cmap, ylabel = area_percent_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for euv_date_str in EUV_DATE_LIST[:1]:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}EUV{euv_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'EUV {euv_date_str} comparison already exists.'))\n",
    "        continue\n",
    "\n",
    "    he_date_str = prepare_data.get_latest_date_str(\n",
    "        HE_DATE_LIST, selected_date_str=euv_date_str\n",
    "    )\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_map = prepare_data.get_nso_sunpy_map(ALL_HE_DIR + he_date_str + '.fts')\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "    \n",
    "    # Extract He I observation for mask base and convert to Sunpy map\n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    ) \n",
    "    raw_he = prepare_data.get_image_from_fits(he_fits_file)\n",
    "    he_base_data = np.where(raw_he == raw_he[0,0], np.NaN, raw_he)\n",
    "    he_base_map = sunpy.map.Map(np.flipud(he_base_data), he_map.meta)\n",
    "    \n",
    "    # Extract saved single mask array and convert to Sunpy map\n",
    "    mask_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    mask_data = np.load(mask_file, allow_pickle=True)[-1]\n",
    "    mask_map = sunpy.map.Map(np.flipud(mask_data), he_map.meta)\n",
    "    mask_map.plot_settings['cmap'] = colormaps['gray']\n",
    "    \n",
    "    euv_map = sunpy.map.Map(ALL_EUV_DIR + euv_date_str + '.fts')\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    \n",
    "    plot_detection.plot_he_map(fig, (2, 3, 1), he_map, he_date_str)\n",
    "    \n",
    "    # Plot He I observation with overlayed detection contours\n",
    "    ax = fig.add_subplot(232, projection=he_map)\n",
    "    he_base_map.plot(axes=ax, vmin=-100, vmax=100, title=he_date_str,\n",
    "                     cmap='afmhot')\n",
    "    for contour in mask_map.contour(0):\n",
    "        ax.plot_coord(contour, color='black', linewidth=1)\n",
    "    \n",
    "    plot_detection.plot_euv_map(fig, (2, 3, 3), euv_map, euv_date_str)\n",
    "    \n",
    "    ax = fig.add_subplot(2, 3, (4, 6))\n",
    "    plot_detection.plot_outcome_series_vs_time(\n",
    "        ax, outcome_time_series_dict[outcome_key], he_date_str, cmap,\n",
    "        ylabel, ylim=[0,3.75]\n",
    "    )\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'{euv_date_str} map comparison saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.2-v0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_level_list = [1, 50, 75, 95]\n",
    "# confidence_level_list = [0, 35, 65, 95]\n",
    "outcome_time_series_dict = detect.get_outcome_time_series_dict(\n",
    "    HE_DATE_LIST, confidence_level_list, DETECTION_SAVE_DIR\n",
    ")\n",
    "outcome_time_series_dict['area_percent'][50].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "region_num_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'Region_Number/',\n",
    "    'num_ch', 'viridis', 'Detected CH Number'\n",
    ")\n",
    "px_percent_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'EUV_Px_Percentage/',\n",
    "    'px_percent', 'plasma', 'Detected Pixel Percentage (%)'\n",
    ")\n",
    "area_percent_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'EUV_Area_Percentage/',\n",
    "    'area_percent', 'plasma', 'Detected Area Percentage (%)'\n",
    ")\n",
    "area_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'EUV_Area/',\n",
    "    'area', 'plasma', 'Detected Area (Mm^2)'\n",
    ")\n",
    "out_dir, outcome_key, cmap, ylabel = area_percent_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for euv_date_str in EUV_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}EUV{euv_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'EUV {euv_date_str} comparison already exists.'))\n",
    "        continue\n",
    "    \n",
    "    he_date_str = prepare_data.get_latest_date_str(\n",
    "        HE_DATE_LIST, selected_date_str=euv_date_str\n",
    "    )\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_map = prepare_data.get_nso_sunpy_map(ALL_HE_DIR + he_date_str + '.fts')\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "    \n",
    "    # Extract saved ensemble map array and convert to Sunpy map\n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    ensemble_map_data = np.load(ensemble_file, allow_pickle=True)[-1]\n",
    "    ensemble_map = sunpy.map.Map(np.flipud(ensemble_map_data), he_map.meta)\n",
    "    ensemble_map.plot_settings['cmap'] = colormaps['magma']\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    plot_detection.plot_he_neutral_lines_euv_comparison(\n",
    "        fig, he_date_str, mag_date_str, euv_date_str,\n",
    "        ROTATED_MAG_SAVE_DIR, nrows=2\n",
    "    )\n",
    "    \n",
    "    ax = fig.add_subplot(2, 3, (4, 6))\n",
    "    plot_detection.plot_outcome_df_vs_time(\n",
    "        ax, outcome_time_series_dict[outcome_key], he_date_str, cmap, ylabel\n",
    "    )\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'{euv_date_str} map comparison saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.5.1+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_level_list = [50, 75, 95]\n",
    "# confidence_level_list = [1, 50, 75, 95]\n",
    "# confidence_level_list = [0, 35, 65, 95]\n",
    "outcome_time_series_dict = detect.get_outcome_time_series_dict_v0_5_1(\n",
    "    HE_DATE_LIST, confidence_level_list, DETECTION_MAP_SAVE_DIR\n",
    ")\n",
    "outcome_time_series_dict['area_percent'][50].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "region_num_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'Region_Number/',\n",
    "    'num_ch', 'viridis', 'Detected CH Number'\n",
    ")\n",
    "px_percent_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'EUV_Px_Percentage/',\n",
    "    'px_percent', 'plasma', 'Detected Pixel Percentage (%)'\n",
    ")\n",
    "area_percent_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'EUV_Area_Percentage/',\n",
    "    'area_percent', 'plasma', 'Detected Area Percentage (%)'\n",
    ")\n",
    "area_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'EUV_Area/',\n",
    "    'area', 'plasma', 'Detected Area (Mm^2)'\n",
    ")\n",
    "out_dir, outcome_key, cmap, ylabel = area_percent_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_reproject = False\n",
    "\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for euv_date_str in EUV_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}EUV{euv_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'EUV {euv_date_str} comparison already exists.'))\n",
    "        continue\n",
    "    \n",
    "    he_date_str = prepare_data.get_latest_date_str(\n",
    "        HE_DATE_LIST, selected_date_str=euv_date_str\n",
    "    )\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    if hg_reproject:\n",
    "        fig = plt.figure(figsize=(22, 10))\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(18, 10))\n",
    "    \n",
    "    plot_detection.plot_he_neutral_lines_euv_v0_5_1(\n",
    "        fig, he_date_str, mag_date_str, euv_date_str,\n",
    "        nrows=2, hg_reproject=False\n",
    "    )\n",
    "    \n",
    "    if hg_reproject:\n",
    "        ax = fig.add_subplot(2, 7, (8, 14))\n",
    "    else:\n",
    "        ax = fig.add_subplot(2, 3, (4, 6))\n",
    "    \n",
    "    plot_detection.plot_outcome_df_vs_time(\n",
    "        ax, outcome_time_series_dict[outcome_key], he_date_str, cmap,\n",
    "        ylabel, #ylim=[0,3.75]\n",
    "    )\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'{euv_date_str} map comparison saved.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare outcomes between confidence levels and/or methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = DETECT_DIR + '_Outcome_Comparison/' + DATE_DIR\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# confidence_level_list = [0, 35, 65, 95]\n",
    "confidence_level_list = [0, 50, 80]\n",
    "# confidence_level_list = list(range(0,96,5))\n",
    "\n",
    "# version_dirs = ['v0_3/', 'Band_Pass/', 'Rescale/', 'Rescale_Center/']\n",
    "# version_dirs = ['v0_3/', 'Rescale/']\n",
    "# version_dirs = ['v0_3/', 'Rescale/', 'v0_4/']\n",
    "# version_dirs = ['v0_3/', 'v0_4/']\n",
    "# version_dirs = ['v0_4_Single/', 'v0_4/']\n",
    "# version_dirs = ['v0_4_Unipolar']\n",
    "# version_dirs = ['v0_1', 'v0_2', 'v0_3', 'v0_4', 'v0_5']\n",
    "version_dirs = ['v0_1', 'v0_2', 'v0_4', 'v0_5']\n",
    "descript_list = version_dirs + [f'cl{cl}' for cl in confidence_level_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cl_dx_list = np.arange(-0.3,0.31,0.2)\n",
    "# method_list = ['Bright & Coherent Mask', 'Ensemble', 'Smoothness',\n",
    "#                'Consistency', 'Unipolarity']\n",
    "\n",
    "cl_dx_list = np.arange(-0.2,0.21,0.2)\n",
    "method_list = ['Single Preliminary Mask', 'Area Ensemble',\n",
    "               'Smoothness Ensemble', 'Unipolarity Ensemble']\n",
    "\n",
    "# cl_dx_list = np.arange(-0.9,0.91,0.2)\n",
    "# method_list = ['Unipolarity']\n",
    "\n",
    "# cl_dx_list = np.arange(0,1,0.05)\n",
    "# method_list = ['Unipolarity']\n",
    "\n",
    "# cl_dx_list = np.arange(-0.3,0.31,0.2)\n",
    "# # method_list = ['v0.3', 'v0.3 Design + Band Pass', 'v0.3 Design + Rescale',\n",
    "# #               'v0.3 Design + Rescale & Center']\n",
    "# method_list = ['v0.1', 'v0.2', 'v0.3', 'v0.4']\n",
    "\n",
    "# cl_dx_list = [-0.1, 0.1]\n",
    "# # method_list = ['v0.3', 'v0.3 Design + Rescale']\n",
    "# # method_list = ['v0.3', 'v0.4']\n",
    "# method_list = ['v0.4 Single', 'v0.4 Ensemble']\n",
    "\n",
    "# cl_dx_list = [-0.2, 0, 0.2]\n",
    "# method_list = ['v0.3', 'v0.3 Design + Rescale', 'v0.4']\n",
    "\n",
    "# cmap = colormaps['viridis']\n",
    "cmap = colormaps['bone_r']\n",
    "color_list = cmap(np.linspace(0.25, 0.9, len(confidence_level_list)))\n",
    "# cmap = colormaps['plasma_r']\n",
    "# color_list = cmap(np.linspace(0.25, 1, len(confidence_level_list)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.2-v0.5 Compute Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_percent_df_by_method_list = []\n",
    "autocorr_by_conf_by_method_list = []\n",
    "mad_by_conf_by_method_list = []\n",
    "norm_mad_by_conf_by_method_list = []\n",
    "\n",
    "\n",
    "for version_dir in version_dirs:\n",
    "    detection_save_dir = os.path.join(DETECT_DIR, version_dir, 'Saved_npy_Files/')\n",
    "    \n",
    "    outcome_time_series_dict = detect.get_outcome_time_series_dict(\n",
    "        HE_DATE_LIST, confidence_level_list, detection_save_dir\n",
    "    )\n",
    "    area_percent_df_by_method_list.append(\n",
    "        outcome_time_series_dict['area_percent']\n",
    "    )\n",
    "    \n",
    "    autocorr_by_confidences = [\n",
    "        outcome_time_series_dict['area'][cl].autocorr()\n",
    "        for cl in confidence_level_list\n",
    "    ]\n",
    "    autocorr_by_conf_by_method_list.append(autocorr_by_confidences)\n",
    "    out = detect.get_mad_by_confidences(\n",
    "        outcome_time_series_dict['area'], confidence_level_list\n",
    "    )\n",
    "    mad_by_confidences, norm_mad_by_confidences = out\n",
    "    mad_by_conf_by_method_list.append(mad_by_confidences)\n",
    "    norm_mad_by_conf_by_method_list.append(norm_mad_by_confidences)\n",
    "    print(f'Outcomes computed for {version_dir}')\n",
    "\n",
    "descript_list = version_dirs + [f'cl{cl}' for cl in confidence_level_list]\n",
    "autocorr_file = f'{out_dir}Autocorr_comp_{\"_\".join(descript_list)}.npy'\n",
    "np.save(autocorr_file, np.array(autocorr_by_conf_by_method_list),\n",
    "        allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.5.1 Compute Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_percent_df_by_method_list = []\n",
    "autocorr_by_conf_by_method_list = []\n",
    "\n",
    "\n",
    "for version_dir in version_dirs:\n",
    "    if 'v0_5_1' in version_dir:\n",
    "        detection_save_dir = os.path.join(\n",
    "            DETECT_DIR, version_dir, 'Saved_fits_Files/'\n",
    "        )\n",
    "        outcome_time_series_dict = detect.get_outcome_time_series_dict_v0_5_1(\n",
    "            HE_DATE_LIST, confidence_level_list, detection_save_dir\n",
    "        )\n",
    "    else:\n",
    "        detection_save_dir = os.path.join(\n",
    "            DETECT_DIR, version_dir, 'Saved_npy_Files/'\n",
    "        )\n",
    "        outcome_time_series_dict = detect.get_outcome_time_series_dict(\n",
    "            HE_DATE_LIST, confidence_level_list, detection_save_dir\n",
    "        )\n",
    "    \n",
    "    area_percent_df_by_method_list.append(\n",
    "        outcome_time_series_dict['area_percent']\n",
    "    )\n",
    "    \n",
    "    autocorr_by_confidences = [\n",
    "        outcome_time_series_dict['area'][cl].autocorr()\n",
    "        for cl in confidence_level_list\n",
    "    ]\n",
    "    autocorr_by_conf_by_method_list.append(autocorr_by_confidences)\n",
    "    print(f'Outcomes computed for {version_dir}')\n",
    "\n",
    "descript_list = version_dirs + [f'cl{cl}' for cl in confidence_level_list]\n",
    "autocorr_file = f'{out_dir}Autocorr_comp_{\"_\".join(descript_list)}.npy'\n",
    "np.save(autocorr_file, np.array(autocorr_by_conf_by_method_list),\n",
    "        allow_pickle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design Variable Sweep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_level = 0\n",
    "area_percent_df = area_percent_df_by_method_list[confidence_level]\n",
    "median_area_percent_by_cl = [\n",
    "    np.median(area_percent_df[cl]) for cl in confidence_level_list\n",
    "]\n",
    "\n",
    "x_ticks = np.arange(len(method_list))\n",
    "plt.figure(1, figsize=(9,6))\n",
    "\n",
    "# Loop over confidence levels to plot bars for all methods at once\n",
    "for median_area_percent, cl_dx, color in zip(\n",
    "    median_area_percent_by_cl, cl_dx_list, color_list):\n",
    "    plt.bar(x_ticks + cl_dx, median_area_percent, width=0.05, color=color)\n",
    "\n",
    "plt.suptitle(DATE_RANGE_SUPTITLE)\n",
    "plt.title('Design Variable Sweep')\n",
    "plt.ylabel('Median Detected Area Percentage (%)')\n",
    "plt.xlabel('Unipolarity Threshold')\n",
    "plt.xlim([-0.025,1.025])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr_file_name = f'{out_dir}Autocorr_comp_{\"_\".join(descript_list)}'\n",
    "autocorrs_by_cl_by_method = np.load(autocorr_file_name + '.npy', allow_pickle=True)\n",
    "autocorrs_by_method_by_cl = autocorrs_by_cl_by_method.T\n",
    "\n",
    "x_ticks = np.arange(len(method_list))\n",
    "\n",
    "plt.figure(1, figsize=(9,6))\n",
    "\n",
    "# Loop over confidence levels to plot bars for all methods at once\n",
    "for autocorrs_by_method, cl_dx, color in zip(\n",
    "    autocorrs_by_method_by_cl, cl_dx_list, color_list):\n",
    "    plt.bar(x_ticks + cl_dx, autocorrs_by_method, width=0.05,\n",
    "            color=color)\n",
    "\n",
    "plt.suptitle(DATE_RANGE_SUPTITLE)\n",
    "plt.title('Design Variable Sweep')\n",
    "plt.ylabel(f'Autocorrelation')\n",
    "plt.xlabel('Unipolarity Threshold')\n",
    "plt.xlim([-0.025,1.025])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation by Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr_file_name = f'{out_dir}Autocorr_comp_{\"_\".join(descript_list)}'\n",
    "autocorrs_by_cl_by_method = np.load(autocorr_file_name + '.npy', allow_pickle=True)\n",
    "autocorrs_by_method_by_cl = autocorrs_by_cl_by_method.T\n",
    "\n",
    "x_ticks = np.arange(len(method_list))\n",
    "confidence_label_list = [\n",
    "    f'{confidence_level}% Confidence'\n",
    "    for confidence_level in confidence_level_list\n",
    "]\n",
    "\n",
    "plt.figure(1, figsize=(10,6))\n",
    "\n",
    "# Loop over confidence levels to plot bars for all methods at once\n",
    "for autocorrs_by_method, cl_dx, confidence, color in zip(\n",
    "    autocorrs_by_method_by_cl, cl_dx_list, confidence_label_list, color_list):\n",
    "    plt.bar(x_ticks + cl_dx, autocorrs_by_method, width=0.2,\n",
    "            label=confidence, color=color)\n",
    "\n",
    "plt.suptitle(DATE_RANGE_SUPTITLE)\n",
    "plt.title('Method Comparison')\n",
    "plt.xticks(x_ticks, method_list)\n",
    "plt.ylabel(f'Time Series Autocorrelation')\n",
    "\n",
    "# plt.ylim([0, 0.8])\n",
    "# plt.ylim([-0.1, 0.8])\n",
    "# plt.axhline(0, color='k', linestyle='--')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Save plot\n",
    "plt.savefig(autocorr_file_name + '.png')\n",
    "plt.close()\n",
    "print(f'{autocorr_file_name.split(\"/\")[-1]} method comparison saved.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5128c55",
   "metadata": {},
   "source": [
    "## Write Images to Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb63d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect.write_video(out_dir, fps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0633f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterlab-debugger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "9702f0bff29bacff409d5ed2ffa7f0a67aa5aa939df8fc4f21a3e6487ad9172c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
