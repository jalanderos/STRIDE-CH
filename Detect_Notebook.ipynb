{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27054106-5f21-4f2a-a320-a24b0e6d0b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sunpy.map\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "from datetime import datetime\n",
    "from matplotlib import colormaps, pyplot as plt\n",
    "\n",
    "import prepare_data\n",
    "import detect\n",
    "import plot_detection\n",
    "from settings import *\n",
    "\n",
    "\n",
    "pio.renderers.default = 'vscode'\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1324d19-b50d-43d3-8875-f4f0ea184bcb",
   "metadata": {},
   "source": [
    "# Data Inspection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f7089cf",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdf30f18",
   "metadata": {},
   "source": [
    "Extract Data from File System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6598a-c954-4bcc-9383-d6ab03b6364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract He I observation datetimes from FITS files\n",
    "HE_DATE_LIST = prepare_data.get_fits_date_list(\n",
    "    DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    ")\n",
    "\n",
    "# Extract magnetogram datetimes from 6302l FITS files\n",
    "MAG_DATE_LIST = prepare_data.get_fits_date_list(\n",
    "    DATE_RANGE, ALL_MAG_DIR, SELECT_MAG_DIR\n",
    ")\n",
    "\n",
    "# Extract EUV datetimes from FITS files\n",
    "EUV_DATE_LIST = prepare_data.get_fits_date_list(\n",
    "    DATE_RANGE, ALL_EUV_DIR, SELECT_EUV_DIR\n",
    ")\n",
    "\n",
    "date_strs = [HE_DATE_LIST[0], HE_DATE_LIST[-1]]\n",
    "file_date_str = f'{date_strs[0]}_{date_strs[-1]}'\n",
    "\n",
    "num_maps = len(HE_DATE_LIST)\n",
    "datetimes = [datetime.strptime(date_str, DICT_DATE_STR_FORMAT)\n",
    "             for date_str in date_strs]\n",
    "title_date_strs = [datetime.strftime(d, '%m/%d/%Y') for d in datetimes]\n",
    "DATE_RANGE_SUPTITLE = (f'{num_maps} Maps Evaluated from '\n",
    "                       + f'{title_date_strs[0]} to {title_date_strs[-1]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f74a10ba-f2a1-401d-b55c-a15d66a7ad18",
   "metadata": {},
   "source": [
    "Rename Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8659fe01-26b6-4ba7-9aac-1e2e62b2c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all gzipped files after renaming\n",
    "remove_gzip = True\n",
    "\n",
    "# Rename all He, magnetogram, and EUV FITS files to include\n",
    "# observation date in title\n",
    "prepare_data.rename_dir(ALL_HE_DIR, remove_gzip)\n",
    "prepare_data.rename_dir(ALL_MAG_DIR, remove_gzip)\n",
    "prepare_data.rename_dir(ALL_EUV_DIR, remove_gzip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EUV Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "DICT_DATE_STR_FORMAT = '%Y_%m_%d__%H_%M'\n",
    "\n",
    "# Dates for which to download EUV observations\n",
    "download_euv_dates = HE_DATE_LIST\n",
    "\n",
    "# Identify missing dates\n",
    "available_datetimes = [datetime.strptime(date_str, DICT_DATE_STR_FORMAT).date()\n",
    "                       for date_str in HE_DATE_LIST]\n",
    "days_in_period = (available_datetimes[-1] - available_datetimes[0]).days\n",
    "all_period_dates = set(available_datetimes[0] + timedelta(num_days)\n",
    "                       for num_days in range(days_in_period))\n",
    "missing_dates = all_period_dates - set(available_datetimes)\n",
    "\n",
    "# Missing datetime strings shifted to noon\n",
    "missing_date_str_list = [\n",
    "    datetime.strftime(missing_date, DICT_DATE_STR_FORMAT)\n",
    "    for missing_date in missing_dates\n",
    "]\n",
    "missing_date_str_list = [\n",
    "    missing_date_str[:12] + '16_00'\n",
    "    for missing_date_str in missing_date_str_list\n",
    "]\n",
    "\n",
    "# Add missing datetimes\n",
    "download_euv_dates.extend(missing_date_str_list)\n",
    "download_euv_dates.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_euv_dates = download_euv_dates[97:98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data.download_euv(download_euv_dates, EUV_DATE_LIST,\n",
    "                          download_dir=ALL_EUV_DIR, hr_window=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from datetime import datetime, timedelta\n",
    "from sunpy.net import Fido, attrs as a\n",
    "\n",
    "\n",
    "date_str = '2012_05_12__18_28'\n",
    "hr_window = 1\n",
    "\n",
    "center_date = datetime.strptime(date_str, DICT_DATE_STR_FORMAT)\n",
    "        \n",
    "min_date = center_date - timedelta(hours=hr_window)\n",
    "max_date = center_date + timedelta(hours=hr_window)\n",
    "\n",
    "result = Fido.search(\n",
    "    a.Time(min_date, max_date),\n",
    "    a.Instrument.aia, a.Wavelength(193*u.angstrom),\n",
    "    a.Sample(30*u.minute), \n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_num = 2\n",
    "download_dir = ALL_EUV_DIR\n",
    "\n",
    "Fido.fetch(result[:, row_num], path=download_dir + '{file}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6181f045-b741-4915-a11b-e6e127064fab",
   "metadata": {},
   "source": [
    "## Available Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb53e85c-08e3-4ea4-b224-2f95076b967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Available Datetimes for He I Observations:')\n",
    "prepare_data.display_dates(HE_DATE_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Available Datetimes for Magnetograms:')\n",
    "prepare_data.display_dates(MAG_DATE_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Available Datetimes for EUV Observations:')\n",
    "prepare_data.display_dates(EUV_DATE_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magnetogram & EUV Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_size_percent = 10\n",
    "\n",
    "for he_date_str in HE_DATE_LIST[:2]:\n",
    "\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    euv_date_str = prepare_data.get_nearest_date_str(\n",
    "        date_str_list=EUV_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "\n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    )\n",
    "    mag_fits_file = prepare_data.get_fits_path(\n",
    "        mag_date_str, DATE_RANGE, ALL_MAG_DIR, SELECT_MAG_DIR\n",
    "    )\n",
    "    euv_fits_file = prepare_data.get_fits_path(\n",
    "        euv_date_str, DATE_RANGE, ALL_EUV_DIR, SELECT_EUV_DIR\n",
    "    )\n",
    "    he_map = prepare_data.get_solis_sunpy_map(he_fits_file)\n",
    "    mag_map = prepare_data.get_solis_sunpy_map(mag_fits_file)\n",
    "    euv_map = sunpy.map.Map(euv_fits_file)\n",
    "\n",
    "    # Process magnetogram\n",
    "    smoothed_mag_map = prepare_data.get_smoothed_map(mag_map, smooth_size_percent)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "    ax = fig.add_subplot(131, projection=he_map)\n",
    "    he_map.plot(axes=ax, vmin=-100, vmax=100, title=he_date_str)\n",
    "\n",
    "    ax = fig.add_subplot(132, projection=mag_map)\n",
    "    mag_map.plot(axes=ax, vmin=-50, vmax=50, title=mag_date_str)\n",
    "    plot_detection.plot_map_contours(ax, smoothed_mag_map)\n",
    "    \n",
    "    ax = fig.add_subplot(133, projection=euv_map)\n",
    "    euv_map.plot(axes=ax, title=euv_date_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24becfa3-4634-43f1-b5c5-9c463459948c",
   "metadata": {},
   "source": [
    "# Data Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1db2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "he_date_str = HE_DATE_LIST[0]\n",
    "percent_of_peak_list = [80,80, 90, 100,100]\n",
    "morph_radius_list = [18,20, 16, 16,20]\n",
    "\n",
    "\n",
    "# Extract pre-processed map\n",
    "he_fits_file = prepare_data.get_fits_path(\n",
    "    he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    ") \n",
    "# raw_he = prepare_data.get_image_from_fits(he_fits_file)\n",
    "# pre_processed_map_data = detect.pre_process_v0_4(raw_he)\n",
    "he_map = prepare_data.get_solis_sunpy_map(he_fits_file)\n",
    "pre_processed_map = detect.pre_process_vX(he_map)\n",
    "pre_processed_map_data = np.flipud(pre_processed_map.data)\n",
    "\n",
    "out = detect.get_ensemble_v0_3(\n",
    "    pre_processed_map_data, percent_of_peak_list, morph_radius_list\n",
    ")\n",
    "ensemble_map, map_data_by_ch, confidence_list, gradient_medians = out\n",
    "plot_detection.plot_ensemble(\n",
    "    pre_processed_map_data, ensemble_map, map_data_by_ch,\n",
    "    confidence_list, gradient_medians\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e11b12e6",
   "metadata": {},
   "source": [
    "## Pre-Processed Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d74c3567",
   "metadata": {},
   "source": [
    "### Pre-Processed Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019aba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "if not os.path.isdir(PREPROCESS_SAVE_DIR):\n",
    "    os.makedirs(PREPROCESS_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    euv_date_str = prepare_data.get_nearest_date_str(\n",
    "        EUV_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    if os.path.isfile(pre_process_file) and not overwrite:\n",
    "        print((f'He {he_date_str} pre-processed map already exists.'))\n",
    "        continue\n",
    "    \n",
    "    # he_fits_file = prepare_data.get_fits_path(\n",
    "    #     he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    # ) \n",
    "    he_fits_file = f'{RATIO_SAVE_DIR}He{he_date_str}_EUV{euv_date_str}.fits'\n",
    "\n",
    "    raw_he = prepare_data.get_image_from_fits(he_fits_file)\n",
    "    \n",
    "    # pre_processed_map = detect.pre_process_v0_1(raw_he)[0]\n",
    "    pre_processed_map = detect.pre_process_v0_4(raw_he)\n",
    "    \n",
    "    save_list = [he_date_str, pre_processed_map]\n",
    "    np.save(pre_process_file, np.array(save_list, dtype=object), \n",
    "            allow_pickle=True)\n",
    "    print(f'{he_date_str} Pre-Processed Map Saved')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.6+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "if not os.path.isdir(PREPROCESS_MAP_SAVE_DIR):\n",
    "    os.makedirs(PREPROCESS_MAP_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    pre_process_file = (PREPROCESS_MAP_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.fits')\n",
    "    if os.path.isfile(pre_process_file) and not overwrite:\n",
    "        print((f'He {he_date_str} pre-processed map already exists.'))\n",
    "        continue\n",
    "    \n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    )\n",
    "    he_map = prepare_data.get_solis_sunpy_map(he_fits_file)\n",
    "    \n",
    "    pre_processed_map = detect.pre_process_vY(he_map)\n",
    "    \n",
    "    pre_processed_map.save(pre_process_file, overwrite=overwrite)\n",
    "    print(f'{he_date_str} Pre-Processed Map Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprojected Magnetograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differential rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "smooth_size_percent = 10\n",
    "\n",
    "if not os.path.isdir(ROTATED_MAG_SAVE_DIR):\n",
    "    os.makedirs(ROTATED_MAG_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST[1:]:\n",
    "\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    fits_file_name = f'{ROTATED_MAG_SAVE_DIR}Mag{mag_date_str}_He{he_date_str}'\n",
    "    reprojected_fits_file = f'{fits_file_name}.fits'\n",
    "    reprojected_smooth_fits_file = f'{fits_file_name}_smooth.fits'\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    if (os.path.isfile(reprojected_fits_file) or \\\n",
    "        os.path.isfile(reprojected_smooth_fits_file)) and not overwrite:\n",
    "        print((f'{mag_date_str} magnetogram reprojected '\n",
    "                + f'to {he_date_str} already exists.'))\n",
    "        continue\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_map = prepare_data.get_solis_sunpy_map(ALL_HE_DIR + he_date_str + '.fts')\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "    \n",
    "    # Extract Magnetogram observation\n",
    "    mag_map = prepare_data.get_solis_sunpy_map(ALL_MAG_DIR + mag_date_str + '.fts')\n",
    "\n",
    "    # Process magnetogram\n",
    "    reprojected_mag_map = prepare_data.diff_rotate(\n",
    "        input_map=mag_map, target_map=he_map\n",
    "    )\n",
    "    \n",
    "    smoothed_map = prepare_data.get_smoothed_map(mag_map, smooth_size_percent)\n",
    "    reprojected_smooth_map = prepare_data.diff_rotate(\n",
    "        input_map=smoothed_map, target_map=he_map\n",
    "    )\n",
    "    \n",
    "    # Save to FITS files\n",
    "    reprojected_mag_map.save(reprojected_fits_file, overwrite=overwrite)\n",
    "    reprojected_smooth_map.save(f'{fits_file_name}_smooth.fits', overwrite=overwrite)\n",
    "    print(f'{mag_date_str} magnetogram reprojected to {he_date_str} maps saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heliographic reprojection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "smooth_size_percent = 10\n",
    "\n",
    "if not os.path.isdir(HELIOGRAPH_MAG_SAVE_DIR):\n",
    "    os.makedirs(HELIOGRAPH_MAG_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    fits_file_name = f'{HELIOGRAPH_MAG_SAVE_DIR}Mag{mag_date_str}_He{he_date_str}'\n",
    "    reprojected_fits_file = f'{fits_file_name}.fits'\n",
    "    reprojected_smooth_fits_file = f'{fits_file_name}_smooth.fits'\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    if (os.path.isfile(reprojected_fits_file) or \\\n",
    "        os.path.isfile(reprojected_smooth_fits_file)) and not overwrite:\n",
    "        print((f'{mag_date_str} magnetogram reprojected '\n",
    "                + f'to {he_date_str} already exists.'))\n",
    "        continue\n",
    "    \n",
    "    # Extract observations\n",
    "    pre_process_file = (PREPROCESS_MAP_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.fits')\n",
    "    pre_processed_map = sunpy.map.Map(pre_process_file)\n",
    "    \n",
    "    mag_fits_file = prepare_data.get_fits_path(\n",
    "        mag_date_str, DATE_RANGE, ALL_MAG_DIR, SELECT_MAG_DIR\n",
    "    )\n",
    "    mag_map = prepare_data.get_solis_sunpy_map(mag_fits_file)\n",
    "\n",
    "    # Process magnetogram\n",
    "    hg_mag_map = detect.reproject_to_cea(mag_map)\n",
    "    reprojected_mag_map = hg_mag_map.reproject_to(\n",
    "        pre_processed_map.wcs, algorithm='adaptive'\n",
    "    )\n",
    "    \n",
    "    smoothed_map = prepare_data.get_smoothed_map(mag_map, smooth_size_percent)\n",
    "    hg_smoothed_map = detect.reproject_to_cea(smoothed_map)\n",
    "    reprojected_smooth_map = hg_smoothed_map.reproject_to(\n",
    "        pre_processed_map.wcs, algorithm='adaptive'\n",
    "    )\n",
    "    \n",
    "    # Save to FITS files\n",
    "    reprojected_mag_map.save(reprojected_fits_file, overwrite=overwrite)\n",
    "    reprojected_smooth_map.save(reprojected_smooth_fits_file, overwrite=overwrite)\n",
    "    print(f'{mag_date_str} magnetogram reprojected to {he_date_str} map saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create He/EUV Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "\n",
    "if not os.path.isdir(RATIO_SAVE_DIR):\n",
    "    os.makedirs(RATIO_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "\n",
    "    euv_date_str = prepare_data.get_nearest_date_str(\n",
    "        EUV_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    ratio_fits_file = f'{RATIO_SAVE_DIR}He{he_date_str}_EUV{euv_date_str}.fits'\n",
    "    if os.path.isfile(ratio_fits_file):\n",
    "        if overwrite:\n",
    "            os.remove(ratio_fits_file)\n",
    "        else:\n",
    "            print((f'{he_date_str} to {euv_date_str} ratio already exists.'))\n",
    "            continue\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    )\n",
    "    he_map = prepare_data.get_solis_sunpy_map(he_fits_file)\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "    \n",
    "    # Remove error causing keywords which have invalid ascii content\n",
    "    he_map.meta.pop('history')\n",
    "    he_map.meta.pop('comment')\n",
    "    \n",
    "    # Extract and reproject EUV observation\n",
    "    euv_fits_file = prepare_data.get_fits_path(\n",
    "        euv_date_str, DATE_RANGE, ALL_EUV_DIR, SELECT_EUV_DIR\n",
    "    )\n",
    "    euv_map = sunpy.map.Map(euv_fits_file)\n",
    "    reprojected_euv_map = prepare_data.diff_rotate(\n",
    "        input_map=euv_map, target_map=he_map\n",
    "    )\n",
    "    \n",
    "    # Pre-process He I data via background removal and upper cutoff\n",
    "    he_map_data = np.where(he_map.data == he_map.data[0,0],\n",
    "                           np.nan, he_map.data)\n",
    "    he_map_data = np.where(he_map_data >= np.percentile(he_map_data, 99.9),\n",
    "                           np.nan, he_map_data)\n",
    "    \n",
    "    ratio_data = np.divide(he_map_data, (reprojected_euv_map.data)**0.5)\n",
    "    ratio_map = sunpy.map.Map(ratio_data, he_map.meta)\n",
    "    \n",
    "    # Save to FITS files\n",
    "    ratio_map.save(ratio_fits_file)\n",
    "    print(f'He{he_date_str} to EUV{euv_date_str} ratio saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "percent_of_peak = 80\n",
    "morph_radius = 18\n",
    "\n",
    "\n",
    "if not os.path.isdir(DETECTION_SAVE_DIR):\n",
    "    os.makedirs(DETECTION_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    mask_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    if os.path.isfile(mask_file) and not overwrite:\n",
    "        print((f'He {he_date_str} single mask already exists.'))\n",
    "        continue\n",
    "    \n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    pre_processed_map = np.load(pre_process_file, allow_pickle=True)[-1]\n",
    "\n",
    "    ch_mask = detect.get_ch_mask(\n",
    "        pre_processed_map, percent_of_peak, morph_radius\n",
    "    )\n",
    "    \n",
    "    save_list = [he_date_str, ch_mask]\n",
    "    np.save(mask_file, np.array(save_list, dtype=object), allow_pickle=True)\n",
    "    print(f'{he_date_str} Single Mask Saved')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53525df2",
   "metadata": {},
   "source": [
    "### Ensemble Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "\n",
    "# percent_of_peak_list = [80,80, 90, 100,100]\n",
    "# morph_radius_list = [18,20, 16, 16,20]\n",
    "percent_of_peak_list = [100,100, 110, 120,120]\n",
    "morph_radius_list = [18,20, 16, 16,20]\n",
    "\n",
    "\n",
    "if not os.path.isdir(DETECTION_SAVE_DIR):\n",
    "    os.makedirs(DETECTION_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    if os.path.isfile(ensemble_file) and not overwrite:\n",
    "        print((f'He {he_date_str} ensemble map already exists.'))\n",
    "        continue\n",
    "    \n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    pre_processed_map = np.load(pre_process_file, allow_pickle=True)[-1]\n",
    "\n",
    "    ensemble_map = detect.get_ensemble_v0_3(\n",
    "        pre_processed_map, percent_of_peak_list, morph_radius_list\n",
    "    )[0]\n",
    "    \n",
    "    save_list = [he_date_str, ensemble_map]\n",
    "    np.save(ensemble_file, np.array(save_list, dtype=object), allow_pickle=True)\n",
    "    print(f'{he_date_str} Ensemble Map Saved')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "percent_of_peak_list = [80,80, 90, 100,100]\n",
    "morph_radius_list = [18,20, 16, 16,20]\n",
    "unipolarity_threshold = 0.5\n",
    "\n",
    "\n",
    "if not os.path.isdir(DETECTION_SAVE_DIR):\n",
    "    os.makedirs(DETECTION_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    if os.path.isfile(ensemble_file) and not overwrite:\n",
    "        print((f'He {he_date_str} ensemble map already exists.'))\n",
    "        continue\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_file = f'{ALL_HE_DIR}{he_date_str}.fts'\n",
    "    he_map = prepare_data.get_solis_sunpy_map(he_file)\n",
    "\n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    pre_processed_map_data = np.load(pre_process_file, allow_pickle=True)[-1]\n",
    "    pre_processed_map = sunpy.map.Map(\n",
    "        np.flipud(pre_processed_map_data), he_map.meta\n",
    "    )\n",
    "\n",
    "    # Extract saved processed magnetograms\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    reprojected_fits_file = (f'{ROTATED_MAG_SAVE_DIR}'\n",
    "                            f'Mag{mag_date_str}_He{he_date_str}.fits')\n",
    "    reprojected_mag_map = sunpy.map.Map(reprojected_fits_file)\n",
    "\n",
    "    ensemble_map_data = detect.get_ensemble_v0_5(\n",
    "        pre_processed_map, reprojected_mag_map,\n",
    "        percent_of_peak_list, morph_radius_list,\n",
    "        unipolarity_threshold\n",
    "    )[0]\n",
    "    \n",
    "    save_list = [he_date_str, ensemble_map_data]\n",
    "    np.save(ensemble_file, np.array(save_list, dtype=object), allow_pickle=True)\n",
    "    print(f'{he_date_str} Ensemble Map Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "\n",
    "# percent_of_peak_list = [  62, 68, 73, 80]\n",
    "# morph_radius_list = [11, 13,  8, 10]\n",
    "# unipolarity_threshold = 0.01\n",
    "percent_of_peak_list = [85, 73, 95, 85]\n",
    "morph_radius_list = [   10, 14, 10, 14]\n",
    "unipolarity_threshold = 0.5\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.isdir(DETECTION_MAP_SAVE_DIR):\n",
    "    os.makedirs(DETECTION_MAP_SAVE_DIR)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    ensemble_file = f'{DETECTION_MAP_SAVE_DIR}{he_date_str}_ensemble_map.fits'\n",
    "    if os.path.isfile(ensemble_file) and not overwrite:\n",
    "        print((f'He {he_date_str} ensemble map already exists.'))\n",
    "        continue\n",
    "    \n",
    "    # Extract pre-processed map\n",
    "    pre_process_file = (PREPROCESS_MAP_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.fits')\n",
    "    pre_processed_map = sunpy.map.Map(pre_process_file)\n",
    "\n",
    "    # Extract saved processed magnetograms\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    reprojected_fits_file = (f'{HELIOGRAPH_MAG_SAVE_DIR}'\n",
    "                            f'Mag{mag_date_str}_He{he_date_str}.fits')\n",
    "    reprojected_mag_map = sunpy.map.Map(reprojected_fits_file)\n",
    "\n",
    "    ensemble_map_data = detect.get_ensemble_vY(\n",
    "        pre_processed_map, reprojected_mag_map,\n",
    "        percent_of_peak_list, morph_radius_list,\n",
    "        unipolarity_threshold\n",
    "    )[0]\n",
    "    ensemble_map = sunpy.map.Map(\n",
    "        np.flipud(ensemble_map_data), pre_processed_map.meta\n",
    "    )\n",
    "    \n",
    "    ensemble_map.save(ensemble_file, overwrite=overwrite)\n",
    "    print(f'{he_date_str} Ensemble Map Saved')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Map Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### He & Single Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = DETECTION_IMAGE_DIR + 'Preprocess_Single_Comparison/'\n",
    "\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    pre_processed_map = np.load(pre_process_file, allow_pickle=True)[-1]\n",
    "    \n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    ) \n",
    "    raw_he = prepare_data.get_image_from_fits(he_fits_file)\n",
    "    he = np.where(raw_he == raw_he[0,0], np.NaN, raw_he)\n",
    "    \n",
    "    mask_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ch_mask.npy'\n",
    "    single_mask = np.load(mask_file, allow_pickle=True)[-1]\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    ax[0].set_title(he_date_str, fontsize=24)\n",
    "    ax[0].imshow(pre_processed_map, cmap=plt.cm.gray)\n",
    "    \n",
    "    ax[1].imshow(he, cmap=plt.cm.afmhot, vmin=-100, vmax=100)\n",
    "    ax[1].contour(single_mask, linewidths=2, cmap=plt.cm.gray)\n",
    "\n",
    "    plt.savefig(f'{out_dir}{he_date_str}.jpg')\n",
    "    plt.close(fig)\n",
    "    print(f'{he_date_str} map saved.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e729d01",
   "metadata": {},
   "source": [
    "### He & Ensemble Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795460ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = DETECTION_IMAGE_DIR + 'Preprocess_Comparison/'\n",
    "\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    pre_processed_map = np.load(pre_process_file, allow_pickle=True)[-1]\n",
    "    \n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    ensemble_map = np.load(ensemble_file, allow_pickle=True)[-1]\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    ax[0].set_title(he_date_str, fontsize=24)\n",
    "    ax[0].imshow(pre_processed_map, cmap=plt.cm.gray)\n",
    "    \n",
    "    ax[1].imshow(ensemble_map, cmap=plt.cm.magma)\n",
    "\n",
    "    plt.savefig(f'{out_dir}{he_date_str}.jpg')\n",
    "    plt.close(fig)\n",
    "    print(f'{he_date_str} map saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = DETECTION_IMAGE_DIR + 'Preprocess_Comparison/'\n",
    "\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    pre_process_file = (PREPROCESS_MAP_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.fits')\n",
    "    pre_processed_map = sunpy.map.Map(pre_process_file)\n",
    "    \n",
    "    ensemble_file = f'{DETECTION_MAP_SAVE_DIR}{he_date_str}_ensemble_map.fits'\n",
    "    ensemble_map = sunpy.map.Map(ensemble_file)\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "    ax = fig.add_subplot(1, 5, (1,2), projection=pre_processed_map)\n",
    "    pre_processed_map.plot(axes=ax, title=he_date_str)\n",
    "    \n",
    "    # Plot ensemble map with overlayed neutral lines\n",
    "    ax = fig.add_subplot(1, 5, (3,5), projection=ensemble_map)\n",
    "    ensemble_map.plot(axes=ax, title='', cmap='magma')\n",
    "\n",
    "    plt.savefig(f'{out_dir}{he_date_str}.jpg')\n",
    "    plt.close(fig)\n",
    "    print(f'{he_date_str} map saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### He, Ensemble, Mag, & EUV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "out_dir = DETECTION_IMAGE_DIR + 'Full_Comparison/'\n",
    "smooth_size_percent = 10\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for euv_date_str in EUV_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}EUV{euv_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'EUV {euv_date_str} full comparison already exists.'))\n",
    "        continue\n",
    "\n",
    "    he_date_str = prepare_data.get_latest_date_str(\n",
    "        HE_DATE_LIST, selected_date_str=euv_date_str\n",
    "    )\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_map = prepare_data.get_solis_sunpy_map(ALL_HE_DIR + he_date_str + '.fts')\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "    \n",
    "    mag_map = prepare_data.get_solis_sunpy_map(ALL_MAG_DIR + mag_date_str + '.fts')\n",
    "    euv_map = sunpy.map.Map(ALL_EUV_DIR + euv_date_str + '.fts')\n",
    "\n",
    "    # Process magnetogram\n",
    "    smoothed_mag_map = prepare_data.get_smoothed_map(mag_map, smooth_size_percent)\n",
    "    \n",
    "    # Extract saved ensemble map array and convert to Sunpy map\n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    ensemble_map_data = np.load(ensemble_file, allow_pickle=True)[-1]\n",
    "    ensemble_map = sunpy.map.Map(np.flipud(ensemble_map_data), he_map.meta)\n",
    "    ensemble_map.plot_settings['cmap'] = colormaps['magma']\n",
    "    \n",
    "    fig = plt.figure(figsize=(24, 5))\n",
    "\n",
    "    ax = fig.add_subplot(141, projection=he_map)\n",
    "    he_map.plot(axes=ax, vmin=-100, vmax=100, title=he_date_str)\n",
    "\n",
    "    ax = fig.add_subplot(142, projection=he_map)\n",
    "    ensemble_map.plot(axes=ax, title='')\n",
    "    \n",
    "    ax = fig.add_subplot(143, projection=mag_map)\n",
    "    mag_map.plot(axes=ax, vmin=-50, vmax=50, title=mag_date_str)\n",
    "    plot_detection.plot_map_contours(ax, smoothed_mag_map)\n",
    "    \n",
    "    ax = fig.add_subplot(144, projection=euv_map)\n",
    "    euv_map.plot(axes=ax, title=euv_date_str)\n",
    "    \n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f'{euv_date_str} map comparison saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### He, Ensemble, Mag with Neutral Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = DETECTION_IMAGE_DIR + 'Mag_Comparison/'\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST[-10:]:\n",
    "\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "\n",
    "    # Extract He I observation\n",
    "    he_map = prepare_data.get_solis_sunpy_map(ALL_HE_DIR + he_date_str + '.fts')\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "\n",
    "    # Extract saved processed magnetograms\n",
    "    mag_fits_name = f'{ROTATED_MAG_SAVE_DIR}Mag{mag_date_str}_He{he_date_str}'\n",
    "    reprojected_fits_file = f'{mag_fits_name}.fits'\n",
    "    reprojected_smooth_fits_file = f'{mag_fits_name}_smooth.fits'\n",
    "    reprojected_mag_map = sunpy.map.Map(reprojected_fits_file)\n",
    "    reprojected_smooth_map = sunpy.map.Map(reprojected_smooth_fits_file)\n",
    "    # reprojected_smooth_map = sunpy.map.Map(np.fliplr(reprojected_smooth_map.data), reprojected_smooth_map.meta)\n",
    "\n",
    "    # Extract saved ensemble map array and convert to Sunpy map\n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    ensemble_map_data = np.load(ensemble_file, allow_pickle=True)[-1]\n",
    "    ensemble_map = sunpy.map.Map(np.flipud(ensemble_map_data), he_map.meta)\n",
    "    ensemble_map.plot_settings['cmap'] = colormaps['magma']\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "    ax = fig.add_subplot(131, projection=he_map)\n",
    "    he_map.plot(axes=ax, vmin=-100, vmax=100, title=he_date_str)\n",
    "\n",
    "    ax = fig.add_subplot(132, projection=he_map)\n",
    "    ensemble_map.plot(axes=ax, title='')\n",
    "    plot_detection.plot_map_contours(ax, reprojected_smooth_map)\n",
    "\n",
    "    ax = fig.add_subplot(133, projection=he_map)\n",
    "    reprojected_mag_map.plot(axes=ax, vmin=-50, vmax=50, title=mag_date_str)\n",
    "    plot_detection.plot_map_contours(ax, reprojected_smooth_map)\n",
    "\n",
    "    plt.savefig(f'{out_dir}He{he_date_str}.jpg')\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f'{he_date_str} map comparison saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### He, Ensemble, Neutral Lines, & EUV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "out_dir = DETECTION_IMAGE_DIR + 'EUV_Comparison/'\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for euv_date_str in EUV_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}EUV{euv_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'EUV {euv_date_str} comparison already exists.'))\n",
    "        continue\n",
    "    \n",
    "    he_date_str = prepare_data.get_latest_date_str(\n",
    "        HE_DATE_LIST, selected_date_str=euv_date_str\n",
    "    )\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "    plot_detection.plot_he_neutral_lines_euv_comparison(\n",
    "        fig, he_date_str, mag_date_str, euv_date_str,\n",
    "        ROTATED_MAG_SAVE_DIR\n",
    "    )\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'{euv_date_str} map comparison saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v0.6+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_detection import plot_map_contours\n",
    "\n",
    "\n",
    "def plot_he_neutral_euv_comparison_v0_6(fig, he_date_str, mag_date_str,\n",
    "                                        euv_date_str, nrows=1):\n",
    "    \"\"\"Plot a 3 panel comparison of a saturated He I observation, ensemble map\n",
    "    with neutral lines, and an EUV observation.\n",
    "    \"\"\"\n",
    "    # Extract He I observation\n",
    "    he_map = prepare_data.get_solis_sunpy_map(ALL_HE_DIR + he_date_str + '.fts')\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "    \n",
    "    # Extract saved ensemble map array and convert to Sunpy map\n",
    "    ensemble_file = f'{DETECTION_MAP_SAVE_DIR}{he_date_str}_ensemble_map.fits'\n",
    "    ensemble_map = sunpy.map.Map(ensemble_file)\n",
    "    ensemble_map.plot_settings['cmap'] = colormaps['magma']\n",
    "\n",
    "    # Extract saved processed magnetogram\n",
    "    reprojected_smooth_file = (f'{HELIOGRAPH_MAG_SAVE_DIR}Mag{mag_date_str}'\n",
    "                               + f'_He{he_date_str}_smooth.fits')\n",
    "    reprojected_smooth_map = sunpy.map.Map(reprojected_smooth_file)\n",
    "    \n",
    "    euv_map = sunpy.map.Map(ALL_EUV_DIR + euv_date_str + '.fts')\n",
    "    \n",
    "    # Plot He observation\n",
    "    ax = fig.add_subplot(nrows, 7, (1,2), projection=he_map)\n",
    "    he_map.plot(axes=ax, vmin=-100, vmax=100, title=he_date_str)\n",
    "    \n",
    "    # Plot ensemble map with overlayed neutral lines\n",
    "    ax = fig.add_subplot(nrows, 7, (3,5), projection=ensemble_map)\n",
    "    ensemble_map.plot(axes=ax, title=' ')\n",
    "    plot_map_contours(ax, reprojected_smooth_map)\n",
    "    \n",
    "    # Plot EUV observation\n",
    "    ax = fig.add_subplot(nrows, 7, (6,7), projection=euv_map)\n",
    "    euv_map.plot(axes=ax, title=euv_date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "out_dir = DETECTION_IMAGE_DIR + 'EUV_Comparison/'\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for euv_date_str in EUV_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}EUV{euv_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'EUV {euv_date_str} comparison already exists.'))\n",
    "        continue\n",
    "    \n",
    "    he_date_str = prepare_data.get_latest_date_str(\n",
    "        HE_DATE_LIST, selected_date_str=euv_date_str\n",
    "    )\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    fig = plt.figure(figsize=(22, 5))\n",
    "    plot_he_neutral_euv_comparison_v0_6(\n",
    "        fig, he_date_str, mag_date_str, euv_date_str\n",
    "    )\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'{euv_date_str} map comparison saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "# out_dir = (DETECTION_IMAGE_DIR + '_Version_Comparison'\n",
    "#            + DATE_DIR + 'v0_2_v0_4_Unipolar/')\n",
    "out_dir = (DETECTION_IMAGE_DIR + '_Version_Comparison'\n",
    "           + DATE_DIR + 'v0_5_v0_6/')\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# comparison_version_dir = DETECT_DIR + 'v0_1/' + 'Saved_npy_Files/'\n",
    "comparison_version_dir = DETECT_DIR + 'v0_5/' + 'Saved_npy_Files/'\n",
    "\n",
    "for euv_date_str in EUV_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}EUV{euv_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'EUV {euv_date_str} comparison already exists.'))\n",
    "        continue\n",
    "    \n",
    "    he_date_str = prepare_data.get_latest_date_str(\n",
    "        HE_DATE_LIST, selected_date_str=euv_date_str\n",
    "    )\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_map = prepare_data.get_solis_sunpy_map(ALL_HE_DIR + he_date_str + '.fts')\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "    \n",
    "    # Extract comparison saved ensemble map array and convert to Sunpy map\n",
    "    comparison_file = f'{comparison_version_dir}{he_date_str}_ensemble_map.npy'\n",
    "    comparison_map_data = np.load(comparison_file, allow_pickle=True)[-1]\n",
    "    comparison_map_data = np.where(np.isnan(ensemble_map_data), np.nan, comparison_map_data)\n",
    "    comparison_map = sunpy.map.Map(np.flipud(comparison_map_data), he_map.meta)\n",
    "    \n",
    "    # Extract saved ensemble map array and convert to Sunpy map\n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    ensemble_map_data = np.load(ensemble_file, allow_pickle=True)[-1]\n",
    "    ensemble_map = sunpy.map.Map(np.flipud(ensemble_map_data), he_map.meta)\n",
    "    ensemble_map.plot_settings['cmap'] = colormaps['magma']\n",
    "\n",
    "    \n",
    "    # Extract saved processed magnetogram\n",
    "    reprojected_smooth_file = (f'{ROTATED_MAG_SAVE_DIR}Mag{mag_date_str}'\n",
    "                               + f'_He{he_date_str}_smooth.fits')\n",
    "    reprojected_smooth_map = sunpy.map.Map(reprojected_smooth_file)\n",
    "    \n",
    "    euv_map = sunpy.map.Map(ALL_EUV_DIR + euv_date_str + '.fts')\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 11))\n",
    "    \n",
    "    # Plot He observation\n",
    "    ax = fig.add_subplot(2, 2, 1, projection=he_map)\n",
    "    he_map.plot(axes=ax, vmin=-100, vmax=100, title=he_date_str)\n",
    "    \n",
    "    # Plot EUV observation\n",
    "    ax = fig.add_subplot(2, 2, 2, projection=euv_map)\n",
    "    euv_map.plot(axes=ax, title=euv_date_str)\n",
    "    \n",
    "    # Plot ensemble map with overlayed neutral lines\n",
    "    ax = fig.add_subplot(2, 2, 3, projection=he_map)\n",
    "    comparison_map.plot(axes=ax, title='v0.5')\n",
    "    plot_detection.plot_map_contours(ax, reprojected_smooth_map)\n",
    "    \n",
    "    # Plot ensemble map with overlayed neutral lines\n",
    "    ax = fig.add_subplot(2, 2, 4, projection=he_map)\n",
    "    ensemble_map.plot(axes=ax, title='v0.6')\n",
    "    plot_detection.plot_map_contours(ax, reprojected_smooth_map)\n",
    "\n",
    "    # Save plot\n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'{euv_date_str} map comparison saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EUV Ratio Map Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "out_dir = out_dir + 'Ratio_Comparison/' + DATE_DIR\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}He{he_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'He {he_date_str} ratio comparison already exists.'))\n",
    "        continue\n",
    "\n",
    "    euv_date_str = prepare_data.get_nearest_date_str(\n",
    "        EUV_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    # Extract observations and ratio map\n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    )\n",
    "    he_map = prepare_data.get_solis_sunpy_map(he_fits_file)\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "    \n",
    "    euv_fits_file = prepare_data.get_fits_path(\n",
    "        euv_date_str, DATE_RANGE, ALL_EUV_DIR, SELECT_EUV_DIR\n",
    "    )\n",
    "    euv_map = sunpy.map.Map(euv_fits_file)\n",
    "    \n",
    "    ratio_fits_file = f'{RATIO_SAVE_DIR}He{he_date_str}_EUV{euv_date_str}.fits'\n",
    "    ratio_map = sunpy.map.Map(ratio_fits_file)\n",
    "    \n",
    "    # Create panel plot\n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "    ax = fig.add_subplot(131, projection=he_map)\n",
    "    he_map.plot(axes=ax, title=he_date_str, vmin=-100, vmax=100)\n",
    "\n",
    "    ax = fig.add_subplot(132, projection=euv_map)\n",
    "    euv_map.plot(axes=ax, title=euv_date_str)\n",
    "\n",
    "    ax = fig.add_subplot(133, projection=he_map)\n",
    "    ratio_map.plot(axes=ax, cmap='jet', vmin=-1, vmax=6)\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'He {he_date_str} map comparison saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1408e30",
   "metadata": {},
   "source": [
    "Histogram Moments vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ac161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "hist_stat_list = []\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    pre_processed_map_data = np.load(pre_process_file, allow_pickle=True)[-1]\n",
    "    \n",
    "    peak_counts_val = detect.get_peak_counts_loc(\n",
    "        pre_processed_map_data, bins_as_percent=False\n",
    "    )\n",
    "    hist_stat_list.append(\n",
    "        [peak_counts_val, np.nanstd(pre_processed_map_data)]\n",
    "    )\n",
    "\n",
    "# Convert to dataframes\n",
    "datetime_list = [datetime.strptime(he_date_str, DICT_DATE_STR_FORMAT)\n",
    "                 for he_date_str in HE_DATE_LIST]\n",
    "hist_df = pd.DataFrame(\n",
    "    hist_stat_list, columns=['Peak', 'StDev'],\n",
    "    index=datetime_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f564323",
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "out_dir = DETECTION_IMAGE_DIR + 'Histogram_Moments/'\n",
    "cmap = 'plasma'\n",
    "ylabel = 'Histogram Moments'\n",
    "\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    img_file = f'{out_dir}{he_date_str}.jpg'\n",
    "    if os.path.isfile(img_file) and not overwrite:\n",
    "        print((f'He {he_date_str} map already exists.'))\n",
    "        continue\n",
    "    \n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    pre_processed_map = np.load(pre_process_file, allow_pickle=True)[-1]\n",
    "    \n",
    "    hist, edges = detect.get_hist(pre_processed_map,\n",
    "                                         bins_as_percent=False)\n",
    "    \n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    ensemble_map = np.load(ensemble_file, allow_pickle=True)[-1]\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    \n",
    "    ax = fig.add_subplot(231)\n",
    "    ax.set_title(he_date_str)\n",
    "    ax.imshow(pre_processed_map, cmap=plt.cm.gray)\n",
    "    \n",
    "    ax = fig.add_subplot(232)\n",
    "    ax.set_title('Semilog Histogram')\n",
    "    ax.semilogy(edges[1:], hist)\n",
    "    if 'Rescale' in DETECTION_VERSION_DIR:\n",
    "        ax.set_xlim([-1.3, 1.1])\n",
    "        ax.set_ylim([1E2, 5E4])\n",
    "    else:\n",
    "        ax.set_xlim([-110, 110])\n",
    "        ax.set_ylim([1E1, 5E4])\n",
    "    \n",
    "    ax = fig.add_subplot(233)\n",
    "    ax.imshow(ensemble_map, cmap=plt.cm.magma)\n",
    "    \n",
    "    ax = fig.add_subplot(2, 3, (4, 6))\n",
    "    datetimes = hist_df.index\n",
    "    ax.plot(hist_df['StDev'], label='Standard Deviation', linewidth=3)\n",
    "    ax.plot(hist_df['Peak'], label='Mode', linewidth=3)\n",
    "    \n",
    "    # Vertical line for datetime indicator\n",
    "    vline_datetime = datetime.strptime(he_date_str, DICT_DATE_STR_FORMAT)\n",
    "    min_moment = min(hist_df.min())\n",
    "    max_moment = max(hist_df.max())\n",
    "    ax.vlines(x=[vline_datetime, vline_datetime], ymax=2*max_moment, ymin=0,\n",
    "              colors='k', linestyles='dashed')\n",
    "    \n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(45)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    \n",
    "    ax.set_xlim([datetimes[0], datetimes[-1]])\n",
    "    if 'Rescale' in DETECTION_VERSION_DIR:\n",
    "        ax.set_ylim([0.4, 0.8])\n",
    "    else:\n",
    "        ax.set_ylim([0.9*min_moment, 1.1*max_moment])\n",
    "    \n",
    "    ax.legend(reverse=True)\n",
    "\n",
    "    plt.savefig(img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'{he_date_str} map saved.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26b8c418",
   "metadata": {},
   "source": [
    "Pre-Process Outcomes vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94150fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_of_peak_list = [80, 90, 100, 110]\n",
    "num_ch_df, area_percent_df, area_df, px_percent_df = detect.get_thresh_outcome_time_series_dfs(\n",
    "    HE_DATE_LIST, percent_of_peak_list, ALL_HE_DIR, PREPROCESS_SAVE_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4eb45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "out_dir = DETECTION_IMAGE_DIR + 'Thresh_Area_Percentage/'\n",
    "outcome_df = area_percent_df\n",
    "cmap = 'plasma'\n",
    "ylabel = 'Detected Area Percentage (%)'\n",
    "\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for he_date_str in HE_DATE_LIST[24:25]:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    img_file = f'{out_dir}{he_date_str}.jpg'\n",
    "    if os.path.isfile(img_file) and not overwrite:\n",
    "        print((f'He {he_date_str} map already exists.'))\n",
    "        continue\n",
    "    \n",
    "    pre_process_file = (PREPROCESS_SAVE_DIR + he_date_str\n",
    "                        + '_pre_processed_map.npy')\n",
    "    pre_processed_map = np.load(pre_process_file, allow_pickle=True)[-1]\n",
    "    \n",
    "    hist, edges = detect.get_hist(pre_processed_map,\n",
    "                                         bins_as_percent=False)\n",
    "    \n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    ensemble_map = np.load(ensemble_file, allow_pickle=True)[-1]\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    \n",
    "    ax = fig.add_subplot(231)\n",
    "    ax.set_title(he_date_str)\n",
    "    ax.imshow(pre_processed_map, cmap=plt.cm.gray)\n",
    "    \n",
    "    ax = fig.add_subplot(232)\n",
    "    ax.set_title('Semilog Histogram')\n",
    "    ax.semilogy(edges[1:], hist)\n",
    "    if 'Rescale/' in DETECTION_VERSION_DIR:\n",
    "        ax.set_ylim([1E2, 5E4])\n",
    "    else:\n",
    "        ax.set_xlim([-110, 110])\n",
    "        ax.set_ylim([1E1, 5E4])\n",
    "    \n",
    "    ax = fig.add_subplot(233)\n",
    "    ax.imshow(ensemble_map, cmap=plt.cm.magma)\n",
    "    \n",
    "    ax = fig.add_subplot(2, 3, (4, 6))    \n",
    "    plot_detection.plot_thresh_outcome_vs_time(\n",
    "        ax, outcome_df, he_date_str, cmap, ylabel)\n",
    "\n",
    "    plt.savefig(img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'{he_date_str} map saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Mask vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colormaps\n",
    "\n",
    "\n",
    "def get_outcome_series(he_date_str_list, he_dir, DETECTION_SAVE_DIR):\n",
    "    \"\"\"Retrieve series with single mask outcomes over time.\n",
    "    \n",
    "    Args\n",
    "        he_date_str_list: list of date strings for ensemble maps\n",
    "        he_dir: path to directory with saved He I observations\n",
    "        DETECTION_SAVE_DIR: path to directory with saved single masks\n",
    "    Returns\n",
    "        Dataframes of outcomes by confidence level over time.\n",
    "    \"\"\"\n",
    "    # List for outcomes at varied confidence levels and datetimes\n",
    "    num_ch_list = []\n",
    "    area_percent_list = []\n",
    "    area_list = []\n",
    "    px_percent_list = []\n",
    "\n",
    "    for he_date_str in he_date_str_list:\n",
    "        \n",
    "        he_file = f'{he_dir}{he_date_str}.fts'\n",
    "        he_map = prepare_data.get_solis_sunpy_map(he_file)\n",
    "        if not he_map:\n",
    "            print(f'{he_date_str} He I observation extraction failed.')\n",
    "            continue\n",
    "        \n",
    "        # Extract saved single mask\n",
    "        mask_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ch_mask.npy'\n",
    "        mask_data = np.load(mask_file, allow_pickle=True)[-1]\n",
    "        mask_map = sunpy.map.Map(np.flipud(mask_data), he_map.meta)\n",
    "        \n",
    "        # Lists of CH outcomes\n",
    "        num_ch_list.append(detect.get_num_ch(mask_data))\n",
    "        area_tuple = detect.get_open_area(mask_map, confidence_level=0)\n",
    "        area_percent_list.append(area_tuple[0])\n",
    "        area_list.append(area_tuple[1])\n",
    "        px_percent_list.append(detect.get_px_percent(mask_data))\n",
    "    \n",
    "    # Convert to dataframes\n",
    "    datetime_list = [datetime.strptime(he_date_str, DICT_DATE_STR_FORMAT)\n",
    "                    for he_date_str in he_date_str_list]\n",
    "    num_ch_series = pd.Series(\n",
    "        num_ch_list, index=datetime_list\n",
    "    )\n",
    "    area_percent_series = pd.Series(\n",
    "        area_percent_list, index=datetime_list\n",
    "    )\n",
    "    area_series = pd.Series(\n",
    "        area_list, index=datetime_list\n",
    "    )\n",
    "    px_percent_series = pd.Series(\n",
    "        px_percent_list, index=datetime_list\n",
    "    )\n",
    "    return num_ch_series, area_percent_series, area_series, px_percent_series\n",
    "\n",
    "\n",
    "def plot_outcome_vs_time(ax, outcome_series, date_str, cmap, ylabel):\n",
    "    \"\"\"Plot outcome stacked plot vs time for ensemble maps.\n",
    "    \n",
    "    Args\n",
    "        ax: matplotlib axes object to plot on\n",
    "        outcome_series: Pandas dataframe of outcome by confidence level\n",
    "            over time\n",
    "        date_str: Date string at which to plot a vertical line\n",
    "        cmap: Matplotlib colormap name\n",
    "        ylabel: string for y axis label\n",
    "    \"\"\"\n",
    "    datetimes = outcome_series.index\n",
    "    ax.fill_between(datetimes, outcome_series, 0, color=colormaps[cmap](0.75))\n",
    "    \n",
    "    # Vertical line for datetime indicator\n",
    "    vline_datetime = datetime.strptime(date_str, DICT_DATE_STR_FORMAT)\n",
    "    max_outcome = outcome_series.max()\n",
    "    ax.vlines(x=[vline_datetime, vline_datetime], ymax=1.2*max_outcome, ymin=0,\n",
    "              colors='k', linestyles='dashed')\n",
    "    \n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(45)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlim([datetimes[0], datetimes[-1]])\n",
    "    ax.set_ylim([0, 1.1*max_outcome])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ch_series, area_percent_series, area_series, px_percent_series = get_outcome_series(\n",
    "    HE_DATE_LIST, ALL_HE_DIR, DETECTION_SAVE_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "region_num_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'Single_Region_Number/',\n",
    "    num_ch_series, 'viridis', 'Detected CH Number'\n",
    ")\n",
    "px_percent_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'Single_EUV_Px_Percentage/',\n",
    "    px_percent_series, 'plasma', 'Detected Pixel Percentage (%)'\n",
    ")\n",
    "area_percent_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'Single_EUV_Area_Percentage/',\n",
    "    area_percent_series, 'plasma', 'Detected Area Percentage (%)'\n",
    ")\n",
    "area_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'Single_EUV_Area/',\n",
    "    area_series, 'plasma', 'Detected Area (Mm^2)'\n",
    ")\n",
    "out_dir, outcome_series, cmap, ylabel = area_percent_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for euv_date_str in EUV_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}EUV{euv_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'EUV {euv_date_str} comparison already exists.'))\n",
    "        continue\n",
    "\n",
    "    he_date_str = prepare_data.get_latest_date_str(\n",
    "        HE_DATE_LIST, selected_date_str=euv_date_str\n",
    "    )\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_map = prepare_data.get_solis_sunpy_map(ALL_HE_DIR + he_date_str + '.fts')\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "    \n",
    "    # Extract He I observation for mask base and convert to Sunpy map\n",
    "    he_fits_file = prepare_data.get_fits_path(\n",
    "        he_date_str, DATE_RANGE, ALL_HE_DIR, SELECT_HE_DIR\n",
    "    ) \n",
    "    raw_he = prepare_data.get_image_from_fits(he_fits_file)\n",
    "    he_base_data = np.where(raw_he == raw_he[0,0], np.NaN, raw_he)\n",
    "    he_base_map = sunpy.map.Map(np.flipud(he_base_data), he_map.meta)\n",
    "    he_base_map.plot_settings['cmap'] = colormaps['afmhot']\n",
    "    \n",
    "    # Extract saved single mask array and convert to Sunpy map\n",
    "    mask_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ch_mask.npy'\n",
    "    mask_data = np.load(mask_file, allow_pickle=True)[-1]\n",
    "    mask_map = sunpy.map.Map(np.flipud(mask_data), he_map.meta)\n",
    "    mask_map.plot_settings['cmap'] = colormaps['gray']\n",
    "    \n",
    "    euv_map = sunpy.map.Map(ALL_EUV_DIR + euv_date_str + '.fts')\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    \n",
    "    # Plot He observation\n",
    "    ax = fig.add_subplot(231, projection=he_map)\n",
    "    he_map.plot(axes=ax, vmin=-100, vmax=100, title=he_date_str)\n",
    "    \n",
    "    # Plot ensemble map with overlayed neutral lines\n",
    "    ax = fig.add_subplot(232, projection=he_map)\n",
    "    he_base_map.plot(axes=ax, vmin=-100, vmax=100, title=he_date_str)\n",
    "    for contour in mask_map.contour(0):\n",
    "        ax.plot_coord(contour, color='black', linewidth=1)\n",
    "    \n",
    "    # Plot EUV observation\n",
    "    ax = fig.add_subplot(233, projection=euv_map)\n",
    "    euv_map.plot(axes=ax, title=euv_date_str)\n",
    "    \n",
    "    ax = fig.add_subplot(2, 3, (4, 6))\n",
    "    plot_outcome_vs_time(ax, outcome_series, he_date_str, cmap, ylabel)\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'{euv_date_str} map comparison saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_level_list = [1, 50, 75, 95]\n",
    "# confidence_level_list = [0, 35, 65, 95]\n",
    "num_ch_df, area_percent_df, area_df, px_percent_df = detect.get_outcome_time_series_dfs(\n",
    "    HE_DATE_LIST, confidence_level_list, ALL_HE_DIR, DETECTION_SAVE_DIR\n",
    ")\n",
    "area_percent_df[50].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "region_num_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'Region_Number/',\n",
    "    num_ch_df, 'viridis', 'Detected CH Number'\n",
    ")\n",
    "px_percent_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'EUV_Px_Percentage/',\n",
    "    px_percent_df, 'plasma', 'Detected Pixel Percentage (%)'\n",
    ")\n",
    "area_percent_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'EUV_Area_Percentage/',\n",
    "    area_percent_df, 'plasma', 'Detected Area Percentage (%)'\n",
    ")\n",
    "area_settings = (\n",
    "    DETECTION_IMAGE_DIR + 'EUV_Area/',\n",
    "    area_df, 'plasma', 'Detected Area (Mm^2)'\n",
    ")\n",
    "out_dir, outcome_df, cmap, ylabel = area_percent_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for euv_date_str in EUV_DATE_LIST:\n",
    "    \n",
    "    # Optionally overwrite existing files\n",
    "    comparison_img_file = f'{out_dir}EUV{euv_date_str}.jpg'\n",
    "    if os.path.isfile(comparison_img_file) and not overwrite:\n",
    "        print((f'EUV {euv_date_str} comparison already exists.'))\n",
    "        continue\n",
    "    \n",
    "    he_date_str = prepare_data.get_latest_date_str(\n",
    "        HE_DATE_LIST, selected_date_str=euv_date_str\n",
    "    )\n",
    "    mag_date_str = prepare_data.get_nearest_date_str(\n",
    "        MAG_DATE_LIST, selected_date_str=he_date_str\n",
    "    )\n",
    "    \n",
    "    # Extract He I observation\n",
    "    he_map = prepare_data.get_solis_sunpy_map(ALL_HE_DIR + he_date_str + '.fts')\n",
    "    if not he_map:\n",
    "        print(f'{he_date_str} He I observation extraction failed.')\n",
    "        continue\n",
    "    \n",
    "    # Extract saved ensemble map array and convert to Sunpy map\n",
    "    ensemble_file = f'{DETECTION_SAVE_DIR}{he_date_str}_ensemble_map.npy'\n",
    "    ensemble_map_data = np.load(ensemble_file, allow_pickle=True)[-1]\n",
    "    ensemble_map = sunpy.map.Map(np.flipud(ensemble_map_data), he_map.meta)\n",
    "    ensemble_map.plot_settings['cmap'] = colormaps['magma']\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    plot_detection.plot_he_neutral_lines_euv_comparison(\n",
    "        fig, he_date_str, mag_date_str, euv_date_str,\n",
    "        ROTATED_MAG_SAVE_DIR, nrows=2\n",
    "    )\n",
    "    \n",
    "    ax = fig.add_subplot(2, 3, (4, 6))\n",
    "    plot_detection.plot_outcome_vs_time(\n",
    "        ax, outcome_df, he_date_str, cmap, ylabel)\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(comparison_img_file)\n",
    "    plt.close(fig)\n",
    "    print(f'{euv_date_str} map comparison saved.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Process Outcomes vs Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_of_peak_list = [80, 90, 100, 110]\n",
    "area_percent_df_by_method_list = []\n",
    "mad_by_thresh_by_method_list = []\n",
    "\n",
    "for pre_process_save_dir in ['Preprocess_Files_v0_0/', 'Preprocess_Files_v0_4/']:\n",
    "    pre_process_save_dir = out_dir + pre_process_save_dir\n",
    "    \n",
    "    area_percent_df = detect.get_thresh_outcome_time_series_dfs(\n",
    "        HE_DATE_LIST, percent_of_peak_list, ALL_HE_DIR, pre_process_save_dir\n",
    "    )[1]\n",
    "    area_percent_df_by_method_list.append(area_percent_df)\n",
    "    mad_by_thresh_by_method_list.append(\n",
    "        detect.get_mad_by_confidences(area_percent_df, percent_of_peak_list)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ticks = np.arange(len(percent_of_peak_list))\n",
    "threshold_label_list = [\n",
    "    f'{thresh_level}% of Peak Threshold'\n",
    "    for thresh_level in percent_of_peak_list\n",
    "]\n",
    "\n",
    "plt.figure(1, figsize=(8,6))\n",
    "\n",
    "plt.bar(x_ticks - 0.2, mad_by_thresh_by_method_list[0], width=0.2, label='v0.3')\n",
    "plt.bar(x_ticks, mad_by_thresh_by_method_list[1], width=0.2, label='Band Pass')\n",
    "plt.bar(x_ticks + 0.2, mad_by_thresh_by_method_list[2], width=0.2, label='Rescaling')\n",
    "plt.xticks(x_ticks, threshold_label_list, rotation=10)\n",
    "plt.ylabel(f'MAD of Detected Area Percentage (%)')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare outcomes between confidence levels and/or methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = DETECT_DIR + '_Outcome_Comparison/' + DATE_DIR\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "confidence_level_list = [0, 35, 65, 95]\n",
    "# confidence_level_list = list(range(0,96,5))\n",
    "\n",
    "# version_dirs = ['v0_3/', 'Band_Pass/', 'Rescale/', 'Rescale_Center/']\n",
    "# version_dirs = ['v0_3/', 'Rescale/']\n",
    "# version_dirs = ['v0_3/', 'Rescale/', 'v0_4/']\n",
    "# version_dirs = ['v0_3/', 'v0_4/']\n",
    "# version_dirs = ['v0_4_Single/', 'v0_4/']\n",
    "# version_dirs = ['v0_4_Unipolar']\n",
    "version_dirs = ['v0_1', 'v0_2', 'v0_3', 'v0_4', 'v0_5']\n",
    "descript_list = version_dirs + [f'cl{cl}' for cl in confidence_level_list]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_percent_df_by_method_list = []\n",
    "autocorr_by_conf_by_method_list = []\n",
    "mad_by_conf_by_method_list = []\n",
    "norm_mad_by_conf_by_method_list = []\n",
    "\n",
    "\n",
    "for version_dir in version_dirs:\n",
    "    ensemble_maps_save_dir = os.path.join(DETECT_DIR, version_dir, 'Saved_Map_Files/')\n",
    "    \n",
    "    area_percent_df, area_df = detect.get_outcome_time_series_dfs(\n",
    "        HE_DATE_LIST, confidence_level_list, ensemble_maps_save_dir\n",
    "    )[1:3]\n",
    "    area_percent_df_by_method_list.append(area_percent_df)\n",
    "    \n",
    "    autocorr_by_confidences = [\n",
    "        area_df[cl].autocorr()\n",
    "        for cl in confidence_level_list\n",
    "    ]\n",
    "    autocorr_by_conf_by_method_list.append(autocorr_by_confidences)\n",
    "    out = detect.get_mad_by_confidences(\n",
    "        area_df, confidence_level_list\n",
    "    )\n",
    "    mad_by_confidences, norm_mad_by_confidences = out\n",
    "    mad_by_conf_by_method_list.append(mad_by_confidences)\n",
    "    norm_mad_by_conf_by_method_list.append(norm_mad_by_confidences)\n",
    "    print(f'Outcomes computed for {version_dir}')\n",
    "\n",
    "descript_list = version_dirs + [f'cl{cl}' for cl in confidence_level_list]\n",
    "autocorr_file = f'{out_dir}Autocorr_comp_{\"_\".join(descript_list)}.npy'\n",
    "np.save(autocorr_file, np.array(autocorr_by_conf_by_method_list),\n",
    "        allow_pickle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_dx_list = np.arange(-0.3,0.31,0.2)\n",
    "method_list = ['Bright & Coherent Mask', 'Ensemble', 'Smoothness',\n",
    "               'Consistency', 'Unipolarity']\n",
    "\n",
    "# cl_dx_list = np.arange(-0.9,0.91,0.2)\n",
    "# method_list = ['Unipolarity']\n",
    "\n",
    "# cl_dx_list = np.arange(0,1,0.05)\n",
    "# method_list = ['Unipolarity']\n",
    "\n",
    "# cl_dx_list = np.arange(-0.3,0.31,0.2)\n",
    "# # method_list = ['v0.3', 'v0.3 Design + Band Pass', 'v0.3 Design + Rescale',\n",
    "# #               'v0.3 Design + Rescale & Center']\n",
    "# method_list = ['v0.1', 'v0.2', 'v0.3', 'v0.4']\n",
    "\n",
    "# cl_dx_list = [-0.1, 0.1]\n",
    "# # method_list = ['v0.3', 'v0.3 Design + Rescale']\n",
    "# # method_list = ['v0.3', 'v0.4']\n",
    "# method_list = ['v0.4 Single', 'v0.4 Ensemble']\n",
    "\n",
    "# cl_dx_list = [-0.2, 0, 0.2]\n",
    "# method_list = ['v0.3', 'v0.3 Design + Rescale', 'v0.4']\n",
    "\n",
    "cmap = colormaps['viridis']\n",
    "color_list = cmap(np.linspace(0, 0.75, len(confidence_level_list)))\n",
    "# cmap = colormaps['plasma_r']\n",
    "# color_list = cmap(np.linspace(0.25, 1, len(confidence_level_list)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design Variable Sweep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area_file_name = f'{out_dir}Area_comp_{\"_\".join(descript_list)}'\n",
    "area_percent_df = area_percent_df_by_method_list[0]\n",
    "median_area_percent_by_cl = [\n",
    "    np.median(area_percent_df[cl]) for cl in confidence_level_list\n",
    "]\n",
    "\n",
    "x_ticks = np.arange(len(method_list))\n",
    "plt.figure(1, figsize=(9,6))\n",
    "\n",
    "# Loop over confidence levels to plot bars for all methods at once\n",
    "for median_area_percent, cl_dx, color in zip(\n",
    "    median_area_percent_by_cl, cl_dx_list, color_list):\n",
    "    plt.bar(x_ticks + cl_dx, median_area_percent, width=0.05, color=color)\n",
    "\n",
    "plt.suptitle(DATE_RANGE_SUPTITLE)\n",
    "plt.title('Design Variable Sweep')\n",
    "plt.ylabel('Median Detected Area Percentage (%)')\n",
    "plt.xlabel('Unipolarity Threshold')\n",
    "plt.xlim([-0.025,1.025])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr_file_name = f'{out_dir}Autocorr_comp_{\"_\".join(descript_list)}'\n",
    "autocorrs_by_cl_by_method = np.load(autocorr_file_name + '.npy', allow_pickle=True)\n",
    "autocorrs_by_method_by_cl = autocorrs_by_cl_by_method.T\n",
    "\n",
    "x_ticks = np.arange(len(method_list))\n",
    "\n",
    "plt.figure(1, figsize=(9,6))\n",
    "\n",
    "# Loop over confidence levels to plot bars for all methods at once\n",
    "for autocorrs_by_method, cl_dx, color in zip(\n",
    "    autocorrs_by_method_by_cl, cl_dx_list, color_list):\n",
    "    plt.bar(x_ticks + cl_dx, autocorrs_by_method, width=0.05,\n",
    "            color=color)\n",
    "\n",
    "plt.suptitle(DATE_RANGE_SUPTITLE)\n",
    "plt.title('Design Variable Sweep')\n",
    "plt.ylabel(f'Autocorrelation')\n",
    "plt.xlabel('Unipolarity Threshold')\n",
    "plt.xlim([-0.025,1.025])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation by Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr_file_name = f'{out_dir}Autocorr_comp_{\"_\".join(descript_list)}'\n",
    "autocorrs_by_cl_by_method = np.load(autocorr_file_name + '.npy', allow_pickle=True)\n",
    "autocorrs_by_method_by_cl = autocorrs_by_cl_by_method.T\n",
    "\n",
    "x_ticks = np.arange(len(method_list))\n",
    "confidence_label_list = [\n",
    "    f'{confidence_level}% Confidence'\n",
    "    for confidence_level in confidence_level_list\n",
    "]\n",
    "\n",
    "plt.figure(1, figsize=(9,6))\n",
    "\n",
    "# Loop over confidence levels to plot bars for all methods at once\n",
    "for autocorrs_by_method, cl_dx, confidence, color in zip(\n",
    "    autocorrs_by_method_by_cl, cl_dx_list, confidence_label_list, color_list):\n",
    "    plt.bar(x_ticks + cl_dx, autocorrs_by_method, width=0.2,\n",
    "            label=confidence, color=color)\n",
    "\n",
    "plt.suptitle(DATE_RANGE_SUPTITLE)\n",
    "plt.title('Method Comparison')\n",
    "plt.xticks(x_ticks, method_list)\n",
    "plt.ylabel(f'Autocorrelation')\n",
    "\n",
    "# plt.ylim([0, 0.8])\n",
    "# plt.ylim([-0.1, 0.8])\n",
    "# plt.axhline(0, color='k', linestyle='--')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# Save plot\n",
    "plt.savefig(autocorr_file_name + '.png')\n",
    "plt.close()\n",
    "print(f'{autocorr_file_name.split(\"/\")[-1]} method comparison saved.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ticks = np.arange(len(confidence_level_list))\n",
    "confidence_label_list = [\n",
    "    f'{confidence_level}% Confidence'\n",
    "    for confidence_level in confidence_level_list\n",
    "]\n",
    "\n",
    "plt.figure(1, figsize=(9,6))\n",
    "for mad_by_confidences, cl_dx, method, color in zip(\n",
    "    mad_by_conf_by_method_list, cl_dx_list, method_list, color_list):\n",
    "    plt.bar(x_ticks + cl_dx, mad_by_confidences, width=0.2,\n",
    "            label=method, color=color)\n",
    "\n",
    "plt.suptitle(DATE_RANGE_SUPTITLE)\n",
    "plt.title('Method Comparison')\n",
    "plt.xticks(x_ticks, confidence_label_list, rotation=10)\n",
    "plt.ylabel(f'MAD of Detected Area (Mm^2)')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized MAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ticks = np.arange(len(confidence_level_list))\n",
    "confidence_label_list = [\n",
    "    f'{confidence_level}% Confidence'\n",
    "    for confidence_level in confidence_level_list\n",
    "]\n",
    "\n",
    "plt.figure(1, figsize=(9,6))\n",
    "for norm_mad_by_confidences, cl_dx, method, color in zip(\n",
    "    norm_mad_by_conf_by_method_list, cl_dx_list, method_list, color_list):\n",
    "    plt.bar(x_ticks + cl_dx, norm_mad_by_confidences, width=0.2,\n",
    "            label=method, color=color)\n",
    "    \n",
    "plt.suptitle(DATE_RANGE_SUPTITLE)\n",
    "plt.title('Method Comparison')\n",
    "plt.xticks(x_ticks, confidence_label_list, rotation=10)\n",
    "plt.ylim([0, 50])\n",
    "plt.ylabel(f'Normalized MAD of Detected Area (%)')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5128c55",
   "metadata": {},
   "source": [
    "## Write Images to Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb63d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect.write_video(out_dir, fps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0633f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterlab-debugger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "9702f0bff29bacff409d5ed2ffa7f0a67aa5aa939df8fc4f21a3e6487ad9172c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
